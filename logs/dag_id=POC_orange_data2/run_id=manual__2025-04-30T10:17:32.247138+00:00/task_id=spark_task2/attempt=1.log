[2025-04-30T10:17:33.354+0000] {taskinstance.py:1159} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: POC_orange_data2.spark_task2 manual__2025-04-30T10:17:32.247138+00:00 [queued]>
[2025-04-30T10:17:33.363+0000] {taskinstance.py:1159} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: POC_orange_data2.spark_task2 manual__2025-04-30T10:17:32.247138+00:00 [queued]>
[2025-04-30T10:17:33.363+0000] {taskinstance.py:1361} INFO - Starting attempt 1 of 1
[2025-04-30T10:17:33.378+0000] {taskinstance.py:1382} INFO - Executing <Task(PythonOperator): spark_task2> on 2025-04-30 10:17:32.247138+00:00
[2025-04-30T10:17:33.385+0000] {standard_task_runner.py:57} INFO - Started process 232 to run task
[2025-04-30T10:17:33.389+0000] {standard_task_runner.py:84} INFO - Running: ['***', 'tasks', 'run', 'POC_orange_data2', 'spark_task2', 'manual__2025-04-30T10:17:32.247138+00:00', '--job-id', '153', '--raw', '--subdir', 'DAGS_FOLDER/pass_data.py', '--cfg-path', '/tmp/tmpdkbrbfqp']
[2025-04-30T10:17:33.393+0000] {standard_task_runner.py:85} INFO - Job 153: Subtask spark_task2
[2025-04-30T10:17:33.676+0000] {task_command.py:416} INFO - Running <TaskInstance: POC_orange_data2.spark_task2 manual__2025-04-30T10:17:32.247138+00:00 [running]> on host d9ec160e05b6
[2025-04-30T10:17:33.798+0000] {taskinstance.py:1662} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='POC_orange_data2' AIRFLOW_CTX_TASK_ID='spark_task2' AIRFLOW_CTX_EXECUTION_DATE='2025-04-30T10:17:32.247138+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2025-04-30T10:17:32.247138+00:00'
[2025-04-30T10:17:33.798+0000] {logging_mixin.py:154} INFO - === Starting Spark CSV Processing DAG ===
[2025-04-30T10:18:03.752+0000] {logging_mixin.py:154} INFO - [INFO] Spark session successfully created.
[2025-04-30T10:18:03.753+0000] {logging_mixin.py:154} INFO - [INFO] Looking for CSV files in directory: /opt/***/data
[2025-04-30T10:18:03.755+0000] {logging_mixin.py:154} INFO - [INFO] 34 file(s) found for processing.
[2025-04-30T10:18:03.756+0000] {logging_mixin.py:154} INFO - [INFO] Processing file 1/34: /opt/***/data/generated_data_1.csv
[2025-04-30T10:18:17.844+0000] {logging_mixin.py:154} INFO - [INFO] File /opt/***/data/generated_data_1.csv successfully read with 2000000 rows.
[2025-04-30T10:18:17.845+0000] {logging_mixin.py:154} INFO - [INFO] Applying sampling transformation...
[2025-04-30T10:18:20.111+0000] {logging_mixin.py:154} INFO - [INFO] Sampled DataFrame has 600876 rows.
[2025-04-30T10:18:20.112+0000] {logging_mixin.py:154} INFO - [INFO] Writing to Elasticsearch...
[2025-04-30T10:18:22.440+0000] {logging_mixin.py:154} INFO - [ERROR] Failed to process file /opt/***/data/generated_data_1.csv: An error occurred while calling o53.save.
: org.apache.spark.SparkException: Job aborted due to stage failure: Task 7 in stage 8.0 failed 1 times, most recent failure: Lost task 7.0 in stage 8.0 (TID 76) (d9ec160e05b6 executor driver): org.elasticsearch.hadoop.EsHadoopIllegalArgumentException: Cannot determine write shards for [spark_data]; likely its format is incorrect (maybe it contains illegal characters? or all shards failed?)
	at org.elasticsearch.hadoop.util.Assert.isTrue(Assert.java:60)
	at org.elasticsearch.hadoop.rest.RestService.initSingleIndex(RestService.java:689)
	at org.elasticsearch.hadoop.rest.RestService.createWriter(RestService.java:634)
	at org.elasticsearch.spark.rdd.EsRDDWriter.write(EsRDDWriter.scala:71)
	at org.elasticsearch.spark.sql.EsSparkSQL$.$anonfun$saveToEs$1(EsSparkSQL.scala:103)
	at org.elasticsearch.spark.sql.EsSparkSQL$.$anonfun$saveToEs$1$adapted(EsSparkSQL.scala:103)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)
	at org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)
	at org.apache.spark.scheduler.Task.run(Task.scala:141)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:829)

Driver stacktrace:
	at org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2844)
	at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2780)
	at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2779)
	at scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)
	at scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)
	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2779)
	at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1242)
	at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1242)
	at scala.Option.foreach(Option.scala:407)
	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1242)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:3048)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2982)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2971)
	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)
	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:984)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2398)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2419)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2451)
	at org.elasticsearch.spark.sql.EsSparkSQL$.saveToEs(EsSparkSQL.scala:103)
	at org.elasticsearch.spark.sql.ElasticsearchRelation.insert(DefaultSource.scala:629)
	at org.elasticsearch.spark.sql.DefaultSource.createRelation(DefaultSource.scala:107)
	at org.apache.spark.sql.execution.datasources.SaveIntoDataSourceCommand.run(SaveIntoDataSourceCommand.scala:48)
	at org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult$lzycompute(commands.scala:75)
	at org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult(commands.scala:73)
	at org.apache.spark.sql.execution.command.ExecutedCommandExec.executeCollect(commands.scala:84)
	at org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.$anonfun$applyOrElse$1(QueryExecution.scala:107)
	at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)
	at org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)
	at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)
	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
	at org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)
	at org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:107)
	at org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:98)
	at org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:461)
	at org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)
	at org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:461)
	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:32)
	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:267)
	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:263)
	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)
	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)
	at org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:437)
	at org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:98)
	at org.apache.spark.sql.execution.QueryExecution.commandExecuted$lzycompute(QueryExecution.scala:85)
	at org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:83)
	at org.apache.spark.sql.execution.QueryExecution.assertCommandExecuted(QueryExecution.scala:142)
	at org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:859)
	at org.apache.spark.sql.DataFrameWriter.saveToV1Source(DataFrameWriter.scala:388)
	at org.apache.spark.sql.DataFrameWriter.saveInternal(DataFrameWriter.scala:361)
	at org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:248)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)
	at py4j.Gateway.invoke(Gateway.java:282)
	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
	at py4j.commands.CallCommand.execute(CallCommand.java:79)
	at py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)
	at py4j.ClientServerConnection.run(ClientServerConnection.java:106)
	at java.base/java.lang.Thread.run(Thread.java:829)
Caused by: org.elasticsearch.hadoop.EsHadoopIllegalArgumentException: Cannot determine write shards for [spark_data]; likely its format is incorrect (maybe it contains illegal characters? or all shards failed?)
	at org.elasticsearch.hadoop.util.Assert.isTrue(Assert.java:60)
	at org.elasticsearch.hadoop.rest.RestService.initSingleIndex(RestService.java:689)
	at org.elasticsearch.hadoop.rest.RestService.createWriter(RestService.java:634)
	at org.elasticsearch.spark.rdd.EsRDDWriter.write(EsRDDWriter.scala:71)
	at org.elasticsearch.spark.sql.EsSparkSQL$.$anonfun$saveToEs$1(EsSparkSQL.scala:103)
	at org.elasticsearch.spark.sql.EsSparkSQL$.$anonfun$saveToEs$1$adapted(EsSparkSQL.scala:103)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)
	at org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)
	at org.apache.spark.scheduler.Task.run(Task.scala:141)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	... 1 more
[2025-04-30T10:18:22.442+0000] {logging_mixin.py:154} INFO - [INFO] Processing file 2/34: /opt/***/data/generated_data_10.csv
[2025-04-30T10:18:36.452+0000] {logging_mixin.py:154} INFO - [INFO] File /opt/***/data/generated_data_10.csv successfully read with 2000000 rows.
[2025-04-30T10:18:36.453+0000] {logging_mixin.py:154} INFO - [INFO] Applying sampling transformation...
[2025-04-30T10:18:37.624+0000] {logging_mixin.py:154} INFO - [INFO] Sampled DataFrame has 600869 rows.
[2025-04-30T10:18:37.625+0000] {logging_mixin.py:154} INFO - [INFO] Writing to Elasticsearch...
[2025-04-30T10:19:47.506+0000] {logging_mixin.py:154} INFO - [SUCCESS] Successfully processed and indexed: /opt/***/data/generated_data_10.csv
[2025-04-30T10:19:47.509+0000] {logging_mixin.py:154} INFO - [INFO] Processing file 3/34: /opt/***/data/generated_data_11.csv
[2025-04-30T10:19:59.495+0000] {logging_mixin.py:154} INFO - [INFO] File /opt/***/data/generated_data_11.csv successfully read with 2000000 rows.
[2025-04-30T10:19:59.496+0000] {logging_mixin.py:154} INFO - [INFO] Applying sampling transformation...
[2025-04-30T10:20:00.421+0000] {logging_mixin.py:154} INFO - [INFO] Sampled DataFrame has 600869 rows.
[2025-04-30T10:20:00.423+0000] {logging_mixin.py:154} INFO - [INFO] Writing to Elasticsearch...
[2025-04-30T10:20:46.248+0000] {logging_mixin.py:154} INFO - [SUCCESS] Successfully processed and indexed: /opt/***/data/generated_data_11.csv
[2025-04-30T10:20:46.249+0000] {logging_mixin.py:154} INFO - [INFO] Processing file 4/34: /opt/***/data/generated_data_12.csv
[2025-04-30T10:20:56.416+0000] {logging_mixin.py:154} INFO - [INFO] File /opt/***/data/generated_data_12.csv successfully read with 2000000 rows.
[2025-04-30T10:20:56.417+0000] {logging_mixin.py:154} INFO - [INFO] Applying sampling transformation...
[2025-04-30T10:20:57.468+0000] {logging_mixin.py:154} INFO - [INFO] Sampled DataFrame has 600873 rows.
[2025-04-30T10:20:57.468+0000] {logging_mixin.py:154} INFO - [INFO] Writing to Elasticsearch...
[2025-04-30T10:21:38.353+0000] {logging_mixin.py:154} INFO - [SUCCESS] Successfully processed and indexed: /opt/***/data/generated_data_12.csv
[2025-04-30T10:21:38.355+0000] {logging_mixin.py:154} INFO - [INFO] Processing file 5/34: /opt/***/data/generated_data_13.csv
[2025-04-30T10:21:49.518+0000] {logging_mixin.py:154} INFO - [INFO] File /opt/***/data/generated_data_13.csv successfully read with 2000000 rows.
[2025-04-30T10:21:49.519+0000] {logging_mixin.py:154} INFO - [INFO] Applying sampling transformation...
[2025-04-30T10:21:50.877+0000] {logging_mixin.py:154} INFO - [INFO] Sampled DataFrame has 600872 rows.
[2025-04-30T10:21:50.878+0000] {logging_mixin.py:154} INFO - [INFO] Writing to Elasticsearch...
[2025-04-30T10:22:37.413+0000] {logging_mixin.py:154} INFO - [SUCCESS] Successfully processed and indexed: /opt/***/data/generated_data_13.csv
[2025-04-30T10:22:37.414+0000] {logging_mixin.py:154} INFO - [INFO] Processing file 6/34: /opt/***/data/generated_data_14.csv
[2025-04-30T10:22:49.964+0000] {logging_mixin.py:154} INFO - [INFO] File /opt/***/data/generated_data_14.csv successfully read with 2000000 rows.
[2025-04-30T10:22:49.965+0000] {logging_mixin.py:154} INFO - [INFO] Applying sampling transformation...
[2025-04-30T10:22:51.142+0000] {logging_mixin.py:154} INFO - [INFO] Sampled DataFrame has 600867 rows.
[2025-04-30T10:22:51.143+0000] {logging_mixin.py:154} INFO - [INFO] Writing to Elasticsearch...
[2025-04-30T10:23:35.513+0000] {logging_mixin.py:154} INFO - [SUCCESS] Successfully processed and indexed: /opt/***/data/generated_data_14.csv
[2025-04-30T10:23:35.515+0000] {logging_mixin.py:154} INFO - [INFO] Processing file 7/34: /opt/***/data/generated_data_15.csv
[2025-04-30T10:23:46.708+0000] {logging_mixin.py:154} INFO - [INFO] File /opt/***/data/generated_data_15.csv successfully read with 2000000 rows.
[2025-04-30T10:23:46.710+0000] {logging_mixin.py:154} INFO - [INFO] Applying sampling transformation...
[2025-04-30T10:23:47.543+0000] {logging_mixin.py:154} INFO - [INFO] Sampled DataFrame has 600872 rows.
[2025-04-30T10:23:47.544+0000] {logging_mixin.py:154} INFO - [INFO] Writing to Elasticsearch...
[2025-04-30T10:24:25.188+0000] {logging_mixin.py:154} INFO - [SUCCESS] Successfully processed and indexed: /opt/***/data/generated_data_15.csv
[2025-04-30T10:24:25.190+0000] {logging_mixin.py:154} INFO - [INFO] Processing file 8/34: /opt/***/data/generated_data_16.csv
[2025-04-30T10:24:35.477+0000] {logging_mixin.py:154} INFO - [INFO] File /opt/***/data/generated_data_16.csv successfully read with 2000000 rows.
[2025-04-30T10:24:35.478+0000] {logging_mixin.py:154} INFO - [INFO] Applying sampling transformation...
[2025-04-30T10:24:36.246+0000] {logging_mixin.py:154} INFO - [INFO] Sampled DataFrame has 600867 rows.
[2025-04-30T10:24:36.247+0000] {logging_mixin.py:154} INFO - [INFO] Writing to Elasticsearch...
[2025-04-30T10:24:36.927+0000] {logging_mixin.py:154} INFO - [ERROR] Failed to process file /opt/***/data/generated_data_16.csv: An error occurred while calling o153.save.
: org.apache.spark.SparkException: Job aborted due to stage failure: Task 2 in stage 71.0 failed 1 times, most recent failure: Lost task 2.0 in stage 71.0 (TID 708) (d9ec160e05b6 executor driver): org.elasticsearch.hadoop.EsHadoopIllegalArgumentException: Cannot determine write shards for [spark_data]; likely its format is incorrect (maybe it contains illegal characters? or all shards failed?)
	at org.elasticsearch.hadoop.util.Assert.isTrue(Assert.java:60)
	at org.elasticsearch.hadoop.rest.RestService.initSingleIndex(RestService.java:689)
	at org.elasticsearch.hadoop.rest.RestService.createWriter(RestService.java:634)
	at org.elasticsearch.spark.rdd.EsRDDWriter.write(EsRDDWriter.scala:71)
	at org.elasticsearch.spark.sql.EsSparkSQL$.$anonfun$saveToEs$1(EsSparkSQL.scala:103)
	at org.elasticsearch.spark.sql.EsSparkSQL$.$anonfun$saveToEs$1$adapted(EsSparkSQL.scala:103)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)
	at org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)
	at org.apache.spark.scheduler.Task.run(Task.scala:141)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:829)

Driver stacktrace:
	at org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2844)
	at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2780)
	at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2779)
	at scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)
	at scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)
	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2779)
	at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1242)
	at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1242)
	at scala.Option.foreach(Option.scala:407)
	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1242)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:3048)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2982)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2971)
	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)
	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:984)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2398)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2419)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2451)
	at org.elasticsearch.spark.sql.EsSparkSQL$.saveToEs(EsSparkSQL.scala:103)
	at org.elasticsearch.spark.sql.ElasticsearchRelation.insert(DefaultSource.scala:629)
	at org.elasticsearch.spark.sql.DefaultSource.createRelation(DefaultSource.scala:107)
	at org.apache.spark.sql.execution.datasources.SaveIntoDataSourceCommand.run(SaveIntoDataSourceCommand.scala:48)
	at org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult$lzycompute(commands.scala:75)
	at org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult(commands.scala:73)
	at org.apache.spark.sql.execution.command.ExecutedCommandExec.executeCollect(commands.scala:84)
	at org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.$anonfun$applyOrElse$1(QueryExecution.scala:107)
	at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)
	at org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)
	at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)
	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
	at org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)
	at org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:107)
	at org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:98)
	at org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:461)
	at org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)
	at org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:461)
	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:32)
	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:267)
	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:263)
	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)
	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)
	at org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:437)
	at org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:98)
	at org.apache.spark.sql.execution.QueryExecution.commandExecuted$lzycompute(QueryExecution.scala:85)
	at org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:83)
	at org.apache.spark.sql.execution.QueryExecution.assertCommandExecuted(QueryExecution.scala:142)
	at org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:859)
	at org.apache.spark.sql.DataFrameWriter.saveToV1Source(DataFrameWriter.scala:388)
	at org.apache.spark.sql.DataFrameWriter.saveInternal(DataFrameWriter.scala:361)
	at org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:248)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)
	at py4j.Gateway.invoke(Gateway.java:282)
	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
	at py4j.commands.CallCommand.execute(CallCommand.java:79)
	at py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)
	at py4j.ClientServerConnection.run(ClientServerConnection.java:106)
	at java.base/java.lang.Thread.run(Thread.java:829)
Caused by: org.elasticsearch.hadoop.EsHadoopIllegalArgumentException: Cannot determine write shards for [spark_data]; likely its format is incorrect (maybe it contains illegal characters? or all shards failed?)
	at org.elasticsearch.hadoop.util.Assert.isTrue(Assert.java:60)
	at org.elasticsearch.hadoop.rest.RestService.initSingleIndex(RestService.java:689)
	at org.elasticsearch.hadoop.rest.RestService.createWriter(RestService.java:634)
	at org.elasticsearch.spark.rdd.EsRDDWriter.write(EsRDDWriter.scala:71)
	at org.elasticsearch.spark.sql.EsSparkSQL$.$anonfun$saveToEs$1(EsSparkSQL.scala:103)
	at org.elasticsearch.spark.sql.EsSparkSQL$.$anonfun$saveToEs$1$adapted(EsSparkSQL.scala:103)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)
	at org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)
	at org.apache.spark.scheduler.Task.run(Task.scala:141)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	... 1 more
[2025-04-30T10:24:36.928+0000] {logging_mixin.py:154} INFO - [INFO] Processing file 9/34: /opt/***/data/generated_data_17.csv
[2025-04-30T10:24:45.578+0000] {logging_mixin.py:154} INFO - [INFO] File /opt/***/data/generated_data_17.csv successfully read with 2000000 rows.
[2025-04-30T10:24:45.579+0000] {logging_mixin.py:154} INFO - [INFO] Applying sampling transformation...
[2025-04-30T10:24:46.339+0000] {logging_mixin.py:154} INFO - [INFO] Sampled DataFrame has 600869 rows.
[2025-04-30T10:24:46.340+0000] {logging_mixin.py:154} INFO - [INFO] Writing to Elasticsearch...
[2025-04-30T10:25:18.820+0000] {logging_mixin.py:154} INFO - [ERROR] Failed to process file /opt/***/data/generated_data_17.csv: An error occurred while calling o169.save.
: org.apache.spark.SparkException: Job aborted due to stage failure: Task 11 in stage 80.0 failed 1 times, most recent failure: Lost task 11.0 in stage 80.0 (TID 808) (d9ec160e05b6 executor driver): org.elasticsearch.hadoop.EsHadoopException: Could not write all entries for bulk operation [556/556]. Error sample (first [5] error messages):
	org.elasticsearch.hadoop.rest.EsHadoopRemoteException: index_not_found_exception: no such index [spark_data]
	{"index":{}}
{"TimeStamp":2713263300000,"afActiveSessions":0,"afSignallingActiveSessions":2,"amfActiveSessions":7,"fixedActiveSessions":1,"gxCcasInitSuccess@SO1GG2":149,"gxCcasInitSuccess@TN1GG2":1351,"gxCcasInitSuccess@TN2GG2":1073,"gxCcasInitSuccess@TN2VEPG1":1770,"gxCcasTerminateSuccess@SO1GG2":310,"gxCcasTerminateSuccess@TN1GG2":1930,"gxCcasTerminateSuccess@TN2GG2":1111,"gxCcasTerminateSuccess@TN2VEPG1":1072,"gxCcasUpdateSuccess@SO1GG2":154134,"gxCcasUpdateSuccess@TN1GG2":1250,"gxCcasUpdateSuccess@TN2GG2":55571,"gxCcasUpdateSuccess@TN2VEPG1":66934,"gxCcrsInit@SO1GG2":97,"gxCcrsInit@TN1GG2":179,"gxCcrsInit@TN2GG2":732,"gxCcrsInit@TN2VEPG1":1626,"gxCcrsTerminate@SO1GG2":104,"gxCcrsTerminate@TN1GG2":1061,"gxCcrsTerminate@TN2GG2":1637,"gxCcrsTerminate@TN2VEPG1":1569,"gxCcrsUpdate@SO1GG2":1317,"gxCcrsUpdate@TN1GG2":383,"gxCcrsUpdate@TN2GG2":1467,"gxCcrsUpdate@TN2VEPG1":316,"gxQosRequests@SO1GG2":35,"gxQosRequests@TN1GG2":7,"gxQosRequests@TN2GG2":11,"gxQosRequests@TN2VEPG1":48,"gxRaas@SO1GG2":48,"gxRaas@TN1GG2":6,"gxRaas@TN2GG2":34,"gxRaas@TN2VEPG1":26,"gxRaasSuccess@SO1GG2":176101,"gxRaasSuccess@TN1GG2":52,"gxRaasSuccess@TN2GG2":1,"gxRaasSuccess@TN2VEPG1":0,"gxRars@SO1GG2":186,"gxRars@TN1GG2":189,"gxRars@TN2GG2":4,"gxRars@TN2VEPG1":0,"mobileActiveSessions":0,"restGet":1,"rxAaasInitSuccess@rx.so1sbg-pmp1":0,"rxAaasInitSuccess@rx.so1sbg-pmp3":4,"rxAaasInitSuccess@rx.tn2sbg-pmp1":4,"rxAaasSuccess@rx.so1sbg-pmp1":3,"rxAaasSuccess@rx.so1sbg-pmp3":1,"rxAaasSuccess@rx.tn2sbg-pmp1":4,"rxAarsInit@rx.so1sbg-pmp1":3,"rxAarsInit@rx.so1sbg-pmp3":3,"rxAarsInit@rx.tn2sbg-pmp1":3,"rxAarsUpdate@rx.so1sbg-pmp3":3,"rxStasSuccess@rx.so1sbg-pmp1":2,"rxStasSuccess@rx.so1sbg-pmp3":2,"rxStasSuccess@rx.tn2sbg-pmp1":1,"rxStrs@rx.so1sbg-pmp1":3,"rxStrs@rx.so1sbg-pmp3":4,"rxStrs@rx.tn2sbg-pmp1":2,"sdActiveSessions":0,"smfActiveSessions":4,"smpActiveGlobalSessions":4,"subscribers":1}

	org.elasticsearch.hadoop.rest.EsHadoopRemoteException: index_not_found_exception: no such index [spark_data]
	{"index":{}}
{"TimeStamp":2713264200000,"afActiveSessions":3,"afSignallingActiveSessions":1,"amfActiveSessions":7,"fixedActiveSessions":2,"gxCcasInitSuccess@SO1GG2":1501,"gxCcasInitSuccess@TN1GG2":1261,"gxCcasInitSuccess@TN2GG2":603,"gxCcasInitSuccess@TN2VEPG1":1244,"gxCcasTerminateSuccess@SO1GG2":1508,"gxCcasTerminateSuccess@TN1GG2":392,"gxCcasTerminateSuccess@TN2GG2":1846,"gxCcasTerminateSuccess@TN2VEPG1":1299,"gxCcasUpdateSuccess@SO1GG2":199342,"gxCcasUpdateSuccess@TN1GG2":1039,"gxCcasUpdateSuccess@TN2GG2":60368,"gxCcasUpdateSuccess@TN2VEPG1":63113,"gxCcrsInit@SO1GG2":992,"gxCcrsInit@TN1GG2":542,"gxCcrsInit@TN2GG2":198,"gxCcrsInit@TN2VEPG1":797,"gxCcrsTerminate@SO1GG2":1216,"gxCcrsTerminate@TN1GG2":16,"gxCcrsTerminate@TN2GG2":1883,"gxCcrsTerminate@TN2VEPG1":1971,"gxCcrsUpdate@SO1GG2":37,"gxCcrsUpdate@TN1GG2":24,"gxCcrsUpdate@TN2GG2":1579,"gxCcrsUpdate@TN2VEPG1":1157,"gxQosRequests@SO1GG2":34,"gxQosRequests@TN1GG2":7,"gxQosRequests@TN2GG2":18,"gxQosRequests@TN2VEPG1":39,"gxRaas@SO1GG2":35,"gxRaas@TN1GG2":4,"gxRaas@TN2GG2":36,"gxRaas@TN2VEPG1":42,"gxRaasSuccess@SO1GG2":171924,"gxRaasSuccess@TN1GG2":88,"gxRaasSuccess@TN2GG2":1,"gxRaasSuccess@TN2VEPG1":1,"gxRars@SO1GG2":193,"gxRars@TN1GG2":170,"gxRars@TN2GG2":1,"gxRars@TN2VEPG1":2,"mobileActiveSessions":2,"restGet":2,"rxAaasInitSuccess@rx.so1sbg-pmp1":0,"rxAaasInitSuccess@rx.so1sbg-pmp3":3,"rxAaasInitSuccess@rx.tn2sbg-pmp1":0,"rxAaasSuccess@rx.so1sbg-pmp1":0,"rxAaasSuccess@rx.so1sbg-pmp3":3,"rxAaasSuccess@rx.tn2sbg-pmp1":0,"rxAarsInit@rx.so1sbg-pmp1":3,"rxAarsInit@rx.so1sbg-pmp3":2,"rxAarsInit@rx.tn2sbg-pmp1":2,"rxAarsUpdate@rx.so1sbg-pmp3":4,"rxStasSuccess@rx.so1sbg-pmp1":3,"rxStasSuccess@rx.so1sbg-pmp3":0,"rxStasSuccess@rx.tn2sbg-pmp1":2,"rxStrs@rx.so1sbg-pmp1":3,"rxStrs@rx.so1sbg-pmp3":0,"rxStrs@rx.tn2sbg-pmp1":2,"sdActiveSessions":2,"smfActiveSessions":3,"smpActiveGlobalSessions":1,"subscribers":3}

	org.elasticsearch.hadoop.rest.EsHadoopRemoteException: index_not_found_exception: no such index [spark_data]
	{"index":{}}
{"TimeStamp":2713266900000,"afActiveSessions":7,"afSignallingActiveSessions":1,"amfActiveSessions":2,"fixedActiveSessions":4,"gxCcasInitSuccess@SO1GG2":1378,"gxCcasInitSuccess@TN1GG2":1809,"gxCcasInitSuccess@TN2GG2":465,"gxCcasInitSuccess@TN2VEPG1":1390,"gxCcasTerminateSuccess@SO1GG2":383,"gxCcasTerminateSuccess@TN1GG2":1297,"gxCcasTerminateSuccess@TN2GG2":827,"gxCcasTerminateSuccess@TN2VEPG1":770,"gxCcasUpdateSuccess@SO1GG2":189110,"gxCcasUpdateSuccess@TN1GG2":1409,"gxCcasUpdateSuccess@TN2GG2":68332,"gxCcasUpdateSuccess@TN2VEPG1":59842,"gxCcrsInit@SO1GG2":1872,"gxCcrsInit@TN1GG2":1727,"gxCcrsInit@TN2GG2":866,"gxCcrsInit@TN2VEPG1":1104,"gxCcrsTerminate@SO1GG2":397,"gxCcrsTerminate@TN1GG2":277,"gxCcrsTerminate@TN2GG2":1072,"gxCcrsTerminate@TN2VEPG1":733,"gxCcrsUpdate@SO1GG2":1124,"gxCcrsUpdate@TN1GG2":1405,"gxCcrsUpdate@TN2GG2":1678,"gxCcrsUpdate@TN2VEPG1":671,"gxQosRequests@SO1GG2":39,"gxQosRequests@TN1GG2":5,"gxQosRequests@TN2GG2":41,"gxQosRequests@TN2VEPG1":25,"gxRaas@SO1GG2":41,"gxRaas@TN1GG2":1,"gxRaas@TN2GG2":32,"gxRaas@TN2VEPG1":44,"gxRaasSuccess@SO1GG2":173342,"gxRaasSuccess@TN1GG2":73,"gxRaasSuccess@TN2GG2":1,"gxRaasSuccess@TN2VEPG1":0,"gxRars@SO1GG2":170,"gxRars@TN1GG2":155,"gxRars@TN2GG2":3,"gxRars@TN2VEPG1":0,"mobileActiveSessions":3,"restGet":1,"rxAaasInitSuccess@rx.so1sbg-pmp1":0,"rxAaasInitSuccess@rx.so1sbg-pmp3":4,"rxAaasInitSuccess@rx.tn2sbg-pmp1":3,"rxAaasSuccess@rx.so1sbg-pmp1":2,"rxAaasSuccess@rx.so1sbg-pmp3":3,"rxAaasSuccess@rx.tn2sbg-pmp1":4,"rxAarsInit@rx.so1sbg-pmp1":1,"rxAarsInit@rx.so1sbg-pmp3":4,"rxAarsInit@rx.tn2sbg-pmp1":2,"rxAarsUpdate@rx.so1sbg-pmp3":4,"rxStasSuccess@rx.so1sbg-pmp1":1,"rxStasSuccess@rx.so1sbg-pmp3":4,"rxStasSuccess@rx.tn2sbg-pmp1":2,"rxStrs@rx.so1sbg-pmp1":1,"rxStrs@rx.so1sbg-pmp3":1,"rxStrs@rx.tn2sbg-pmp1":2,"sdActiveSessions":1,"smfActiveSessions":3,"smpActiveGlobalSessions":1,"subscribers":2}

	org.elasticsearch.hadoop.rest.EsHadoopRemoteException: index_not_found_exception: no such index [spark_data]
	{"index":{}}
{"TimeStamp":2713269600000,"afActiveSessions":7,"afSignallingActiveSessions":4,"amfActiveSessions":7,"fixedActiveSessions":4,"gxCcasInitSuccess@SO1GG2":642,"gxCcasInitSuccess@TN1GG2":615,"gxCcasInitSuccess@TN2GG2":1432,"gxCcasInitSuccess@TN2VEPG1":1807,"gxCcasTerminateSuccess@SO1GG2":58,"gxCcasTerminateSuccess@TN1GG2":411,"gxCcasTerminateSuccess@TN2GG2":1738,"gxCcasTerminateSuccess@TN2VEPG1":226,"gxCcasUpdateSuccess@SO1GG2":138256,"gxCcasUpdateSuccess@TN1GG2":1367,"gxCcasUpdateSuccess@TN2GG2":51792,"gxCcasUpdateSuccess@TN2VEPG1":62513,"gxCcrsInit@SO1GG2":401,"gxCcrsInit@TN1GG2":777,"gxCcrsInit@TN2GG2":1662,"gxCcrsInit@TN2VEPG1":1289,"gxCcrsTerminate@SO1GG2":1660,"gxCcrsTerminate@TN1GG2":1926,"gxCcrsTerminate@TN2GG2":379,"gxCcrsTerminate@TN2VEPG1":267,"gxCcrsUpdate@SO1GG2":802,"gxCcrsUpdate@TN1GG2":32,"gxCcrsUpdate@TN2GG2":525,"gxCcrsUpdate@TN2VEPG1":1376,"gxQosRequests@SO1GG2":46,"gxQosRequests@TN1GG2":0,"gxQosRequests@TN2GG2":43,"gxQosRequests@TN2VEPG1":49,"gxRaas@SO1GG2":35,"gxRaas@TN1GG2":4,"gxRaas@TN2GG2":14,"gxRaas@TN2VEPG1":10,"gxRaasSuccess@SO1GG2":172179,"gxRaasSuccess@TN1GG2":92,"gxRaasSuccess@TN2GG2":0,"gxRaasSuccess@TN2VEPG1":0,"gxRars@SO1GG2":155,"gxRars@TN1GG2":166,"gxRars@TN2GG2":4,"gxRars@TN2VEPG1":3,"mobileActiveSessions":3,"restGet":2,"rxAaasInitSuccess@rx.so1sbg-pmp1":1,"rxAaasInitSuccess@rx.so1sbg-pmp3":4,"rxAaasInitSuccess@rx.tn2sbg-pmp1":4,"rxAaasSuccess@rx.so1sbg-pmp1":1,"rxAaasSuccess@rx.so1sbg-pmp3":2,"rxAaasSuccess@rx.tn2sbg-pmp1":3,"rxAarsInit@rx.so1sbg-pmp1":3,"rxAarsInit@rx.so1sbg-pmp3":3,"rxAarsInit@rx.tn2sbg-pmp1":0,"rxAarsUpdate@rx.so1sbg-pmp3":2,"rxStasSuccess@rx.so1sbg-pmp1":2,"rxStasSuccess@rx.so1sbg-pmp3":3,"rxStasSuccess@rx.tn2sbg-pmp1":0,"rxStrs@rx.so1sbg-pmp1":3,"rxStrs@rx.so1sbg-pmp3":0,"rxStrs@rx.tn2sbg-pmp1":0,"sdActiveSessions":3,"smfActiveSessions":1,"smpActiveGlobalSessions":3,"subscribers":2}

	org.elasticsearch.hadoop.rest.EsHadoopRemoteException: index_not_found_exception: no such index [spark_data]
	{"index":{}}
{"TimeStamp":2713274100000,"afActiveSessions":3,"afSignallingActiveSessions":2,"amfActiveSessions":1,"fixedActiveSessions":1,"gxCcasInitSuccess@SO1GG2":1466,"gxCcasInitSuccess@TN1GG2":401,"gxCcasInitSuccess@TN2GG2":6,"gxCcasInitSuccess@TN2VEPG1":407,"gxCcasTerminateSuccess@SO1GG2":1435,"gxCcasTerminateSuccess@TN1GG2":1826,"gxCcasTerminateSuccess@TN2GG2":1370,"gxCcasTerminateSuccess@TN2VEPG1":1558,"gxCcasUpdateSuccess@SO1GG2":140667,"gxCcasUpdateSuccess@TN1GG2":1549,"gxCcasUpdateSuccess@TN2GG2":58472,"gxCcasUpdateSuccess@TN2VEPG1":52724,"gxCcrsInit@SO1GG2":1190,"gxCcrsInit@TN1GG2":326,"gxCcrsInit@TN2GG2":570,"gxCcrsInit@TN2VEPG1":947,"gxCcrsTerminate@SO1GG2":808,"gxCcrsTerminate@TN1GG2":1651,"gxCcrsTerminate@TN2GG2":1126,"gxCcrsTerminate@TN2VEPG1":1059,"gxCcrsUpdate@SO1GG2":965,"gxCcrsUpdate@TN1GG2":1102,"gxCcrsUpdate@TN2GG2":180,"gxCcrsUpdate@TN2VEPG1":1773,"gxQosRequests@SO1GG2":38,"gxQosRequests@TN1GG2":8,"gxQosRequests@TN2GG2":48,"gxQosRequests@TN2VEPG1":32,"gxRaas@SO1GG2":37,"gxRaas@TN1GG2":8,"gxRaas@TN2GG2":48,"gxRaas@TN2VEPG1":34,"gxRaasSuccess@SO1GG2":172525,"gxRaasSuccess@TN1GG2":98,"gxRaasSuccess@TN2GG2":0,"gxRaasSuccess@TN2VEPG1":0,"gxRars@SO1GG2":179,"gxRars@TN1GG2":171,"gxRars@TN2GG2":2,"gxRars@TN2VEPG1":4,"mobileActiveSessions":3,"restGet":1,"rxAaasInitSuccess@rx.so1sbg-pmp1":1,"rxAaasInitSuccess@rx.so1sbg-pmp3":0,"rxAaasInitSuccess@rx.tn2sbg-pmp1":3,"rxAaasSuccess@rx.so1sbg-pmp1":3,"rxAaasSuccess@rx.so1sbg-pmp3":1,"rxAaasSuccess@rx.tn2sbg-pmp1":2,"rxAarsInit@rx.so1sbg-pmp1":2,"rxAarsInit@rx.so1sbg-pmp3":1,"rxAarsInit@rx.tn2sbg-pmp1":3,"rxAarsUpdate@rx.so1sbg-pmp3":2,"rxStasSuccess@rx.so1sbg-pmp1":3,"rxStasSuccess@rx.so1sbg-pmp3":1,"rxStasSuccess@rx.tn2sbg-pmp1":0,"rxStrs@rx.so1sbg-pmp1":4,"rxStrs@rx.so1sbg-pmp3":3,"rxStrs@rx.tn2sbg-pmp1":0,"sdActiveSessions":0,"smfActiveSessions":4,"smpActiveGlobalSessions":3,"subscribers":0}

Bailing out...
	at org.elasticsearch.hadoop.rest.bulk.BulkProcessor.flush(BulkProcessor.java:538)
	at org.elasticsearch.hadoop.rest.bulk.BulkProcessor.add(BulkProcessor.java:132)
	at org.elasticsearch.hadoop.rest.RestRepository.doWriteToIndex(RestRepository.java:192)
	at org.elasticsearch.hadoop.rest.RestRepository.writeToIndex(RestRepository.java:172)
	at org.elasticsearch.spark.rdd.EsRDDWriter.write(EsRDDWriter.scala:83)
	at org.elasticsearch.spark.sql.EsSparkSQL$.$anonfun$saveToEs$1(EsSparkSQL.scala:103)
	at org.elasticsearch.spark.sql.EsSparkSQL$.$anonfun$saveToEs$1$adapted(EsSparkSQL.scala:103)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)
	at org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)
	at org.apache.spark.scheduler.Task.run(Task.scala:141)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:829)
	Suppressed: org.apache.spark.util.TaskCompletionListenerException: org.elasticsearch.hadoop.rest.EsHadoopRemoteException: index_not_found_exception: no such index [spark_data]
null

Previous exception in task: Could not write all entries for bulk operation [556/556]. Error sample (first [5] error messages):
	org.elasticsearch.hadoop.rest.EsHadoopRemoteException: index_not_found_exception: no such index [spark_data]
	{"index":{}}
{"TimeStamp":2713263300000,"afActiveSessions":0,"afSignallingActiveSessions":2,"amfActiveSessions":7,"fixedActiveSessions":1,"gxCcasInitSuccess@SO1GG2":149,"gxCcasInitSuccess@TN1GG2":1351,"gxCcasInitSuccess@TN2GG2":1073,"gxCcasInitSuccess@TN2VEPG1":1770,"gxCcasTerminateSuccess@SO1GG2":310,"gxCcasTerminateSuccess@TN1GG2":1930,"gxCcasTerminateSuccess@TN2GG2":1111,"gxCcasTerminateSuccess@TN2VEPG1":1072,"gxCcasUpdateSuccess@SO1GG2":154134,"gxCcasUpdateSuccess@TN1GG2":1250,"gxCcasUpdateSuccess@TN2GG2":55571,"gxCcasUpdateSuccess@TN2VEPG1":66934,"gxCcrsInit@SO1GG2":97,"gxCcrsInit@TN1GG2":179,"gxCcrsInit@TN2GG2":732,"gxCcrsInit@TN2VEPG1":1626,"gxCcrsTerminate@SO1GG2":104,"gxCcrsTerminate@TN1GG2":1061,"gxCcrsTerminate@TN2GG2":1637,"gxCcrsTerminate@TN2VEPG1":1569,"gxCcrsUpdate@SO1GG2":1317,"gxCcrsUpdate@TN1GG2":383,"gxCcrsUpdate@TN2GG2":1467,"gxCcrsUpdate@TN2VEPG1":316,"gxQosRequests@SO1GG2":35,"gxQosRequests@TN1GG2":7,"gxQosRequests@TN2GG2":11,"gxQosRequests@TN2VEPG1":48,"gxRaas@SO1GG2":48,"gxRaas@TN1GG2":6,"gxRaas@TN2GG2":34,"gxRaas@TN2VEPG1":26,"gxRaasSuccess@SO1GG2":176101,"gxRaasSuccess@TN1GG2":52,"gxRaasSuccess@TN2GG2":1,"gxRaasSuccess@TN2VEPG1":0,"gxRars@SO1GG2":186,"gxRars@TN1GG2":189,"gxRars@TN2GG2":4,"gxRars@TN2VEPG1":0,"mobileActiveSessions":0,"restGet":1,"rxAaasInitSuccess@rx.so1sbg-pmp1":0,"rxAaasInitSuccess@rx.so1sbg-pmp3":4,"rxAaasInitSuccess@rx.tn2sbg-pmp1":4,"rxAaasSuccess@rx.so1sbg-pmp1":3,"rxAaasSuccess@rx.so1sbg-pmp3":1,"rxAaasSuccess@rx.tn2sbg-pmp1":4,"rxAarsInit@rx.so1sbg-pmp1":3,"rxAarsInit@rx.so1sbg-pmp3":3,"rxAarsInit@rx.tn2sbg-pmp1":3,"rxAarsUpdate@rx.so1sbg-pmp3":3,"rxStasSuccess@rx.so1sbg-pmp1":2,"rxStasSuccess@rx.so1sbg-pmp3":2,"rxStasSuccess@rx.tn2sbg-pmp1":1,"rxStrs@rx.so1sbg-pmp1":3,"rxStrs@rx.so1sbg-pmp3":4,"rxStrs@rx.tn2sbg-pmp1":2,"sdActiveSessions":0,"smfActiveSessions":4,"smpActiveGlobalSessions":4,"subscribers":1}

	org.elasticsearch.hadoop.rest.EsHadoopRemoteException: index_not_found_exception: no such index [spark_data]
	{"index":{}}
{"TimeStamp":2713264200000,"afActiveSessions":3,"afSignallingActiveSessions":1,"amfActiveSessions":7,"fixedActiveSessions":2,"gxCcasInitSuccess@SO1GG2":1501,"gxCcasInitSuccess@TN1GG2":1261,"gxCcasInitSuccess@TN2GG2":603,"gxCcasInitSuccess@TN2VEPG1":1244,"gxCcasTerminateSuccess@SO1GG2":1508,"gxCcasTerminateSuccess@TN1GG2":392,"gxCcasTerminateSuccess@TN2GG2":1846,"gxCcasTerminateSuccess@TN2VEPG1":1299,"gxCcasUpdateSuccess@SO1GG2":199342,"gxCcasUpdateSuccess@TN1GG2":1039,"gxCcasUpdateSuccess@TN2GG2":60368,"gxCcasUpdateSuccess@TN2VEPG1":63113,"gxCcrsInit@SO1GG2":992,"gxCcrsInit@TN1GG2":542,"gxCcrsInit@TN2GG2":198,"gxCcrsInit@TN2VEPG1":797,"gxCcrsTerminate@SO1GG2":1216,"gxCcrsTerminate@TN1GG2":16,"gxCcrsTerminate@TN2GG2":1883,"gxCcrsTerminate@TN2VEPG1":1971,"gxCcrsUpdate@SO1GG2":37,"gxCcrsUpdate@TN1GG2":24,"gxCcrsUpdate@TN2GG2":1579,"gxCcrsUpdate@TN2VEPG1":1157,"gxQosRequests@SO1GG2":34,"gxQosRequests@TN1GG2":7,"gxQosRequests@TN2GG2":18,"gxQosRequests@TN2VEPG1":39,"gxRaas@SO1GG2":35,"gxRaas@TN1GG2":4,"gxRaas@TN2GG2":36,"gxRaas@TN2VEPG1":42,"gxRaasSuccess@SO1GG2":171924,"gxRaasSuccess@TN1GG2":88,"gxRaasSuccess@TN2GG2":1,"gxRaasSuccess@TN2VEPG1":1,"gxRars@SO1GG2":193,"gxRars@TN1GG2":170,"gxRars@TN2GG2":1,"gxRars@TN2VEPG1":2,"mobileActiveSessions":2,"restGet":2,"rxAaasInitSuccess@rx.so1sbg-pmp1":0,"rxAaasInitSuccess@rx.so1sbg-pmp3":3,"rxAaasInitSuccess@rx.tn2sbg-pmp1":0,"rxAaasSuccess@rx.so1sbg-pmp1":0,"rxAaasSuccess@rx.so1sbg-pmp3":3,"rxAaasSuccess@rx.tn2sbg-pmp1":0,"rxAarsInit@rx.so1sbg-pmp1":3,"rxAarsInit@rx.so1sbg-pmp3":2,"rxAarsInit@rx.tn2sbg-pmp1":2,"rxAarsUpdate@rx.so1sbg-pmp3":4,"rxStasSuccess@rx.so1sbg-pmp1":3,"rxStasSuccess@rx.so1sbg-pmp3":0,"rxStasSuccess@rx.tn2sbg-pmp1":2,"rxStrs@rx.so1sbg-pmp1":3,"rxStrs@rx.so1sbg-pmp3":0,"rxStrs@rx.tn2sbg-pmp1":2,"sdActiveSessions":2,"smfActiveSessions":3,"smpActiveGlobalSessions":1,"subscribers":3}

	org.elasticsearch.hadoop.rest.EsHadoopRemoteException: index_not_found_exception: no such index [spark_data]
	{"index":{}}
{"TimeStamp":2713266900000,"afActiveSessions":7,"afSignallingActiveSessions":1,"amfActiveSessions":2,"fixedActiveSessions":4,"gxCcasInitSuccess@SO1GG2":1378,"gxCcasInitSuccess@TN1GG2":1809,"gxCcasInitSuccess@TN2GG2":465,"gxCcasInitSuccess@TN2VEPG1":1390,"gxCcasTerminateSuccess@SO1GG2":383,"gxCcasTerminateSuccess@TN1GG2":1297,"gxCcasTerminateSuccess@TN2GG2":827,"gxCcasTerminateSuccess@TN2VEPG1":770,"gxCcasUpdateSuccess@SO1GG2":189110,"gxCcasUpdateSuccess@TN1GG2":1409,"gxCcasUpdateSuccess@TN2GG2":68332,"gxCcasUpdateSuccess@TN2VEPG1":59842,"gxCcrsInit@SO1GG2":1872,"gxCcrsInit@TN1GG2":1727,"gxCcrsInit@TN2GG2":866,"gxCcrsInit@TN2VEPG1":1104,"gxCcrsTerminate@SO1GG2":397,"gxCcrsTerminate@TN1GG2":277,"gxCcrsTerminate@TN2GG2":1072,"gxCcrsTerminate@TN2VEPG1":733,"gxCcrsUpdate@SO1GG2":1124,"gxCcrsUpdate@TN1GG2":1405,"gxCcrsUpdate@TN2GG2":1678,"gxCcrsUpdate@TN2VEPG1":671,"gxQosRequests@SO1GG2":39,"gxQosRequests@TN1GG2":5,"gxQosRequests@TN2GG2":41,"gxQosRequests@TN2VEPG1":25,"gxRaas@SO1GG2":41,"gxRaas@TN1GG2":1,"gxRaas@TN2GG2":32,"gxRaas@TN2VEPG1":44,"gxRaasSuccess@SO1GG2":173342,"gxRaasSuccess@TN1GG2":73,"gxRaasSuccess@TN2GG2":1,"gxRaasSuccess@TN2VEPG1":0,"gxRars@SO1GG2":170,"gxRars@TN1GG2":155,"gxRars@TN2GG2":3,"gxRars@TN2VEPG1":0,"mobileActiveSessions":3,"restGet":1,"rxAaasInitSuccess@rx.so1sbg-pmp1":0,"rxAaasInitSuccess@rx.so1sbg-pmp3":4,"rxAaasInitSuccess@rx.tn2sbg-pmp1":3,"rxAaasSuccess@rx.so1sbg-pmp1":2,"rxAaasSuccess@rx.so1sbg-pmp3":3,"rxAaasSuccess@rx.tn2sbg-pmp1":4,"rxAarsInit@rx.so1sbg-pmp1":1,"rxAarsInit@rx.so1sbg-pmp3":4,"rxAarsInit@rx.tn2sbg-pmp1":2,"rxAarsUpdate@rx.so1sbg-pmp3":4,"rxStasSuccess@rx.so1sbg-pmp1":1,"rxStasSuccess@rx.so1sbg-pmp3":4,"rxStasSuccess@rx.tn2sbg-pmp1":2,"rxStrs@rx.so1sbg-pmp1":1,"rxStrs@rx.so1sbg-pmp3":1,"rxStrs@rx.tn2sbg-pmp1":2,"sdActiveSessions":1,"smfActiveSessions":3,"smpActiveGlobalSessions":1,"subscribers":2}

	org.elasticsearch.hadoop.rest.EsHadoopRemoteException: index_not_found_exception: no such index [spark_data]
	{"index":{}}
{"TimeStamp":2713269600000,"afActiveSessions":7,"afSignallingActiveSessions":4,"amfActiveSessions":7,"fixedActiveSessions":4,"gxCcasInitSuccess@SO1GG2":642,"gxCcasInitSuccess@TN1GG2":615,"gxCcasInitSuccess@TN2GG2":1432,"gxCcasInitSuccess@TN2VEPG1":1807,"gxCcasTerminateSuccess@SO1GG2":58,"gxCcasTerminateSuccess@TN1GG2":411,"gxCcasTerminateSuccess@TN2GG2":1738,"gxCcasTerminateSuccess@TN2VEPG1":226,"gxCcasUpdateSuccess@SO1GG2":138256,"gxCcasUpdateSuccess@TN1GG2":1367,"gxCcasUpdateSuccess@TN2GG2":51792,"gxCcasUpdateSuccess@TN2VEPG1":62513,"gxCcrsInit@SO1GG2":401,"gxCcrsInit@TN1GG2":777,"gxCcrsInit@TN2GG2":1662,"gxCcrsInit@TN2VEPG1":1289,"gxCcrsTerminate@SO1GG2":1660,"gxCcrsTerminate@TN1GG2":1926,"gxCcrsTerminate@TN2GG2":379,"gxCcrsTerminate@TN2VEPG1":267,"gxCcrsUpdate@SO1GG2":802,"gxCcrsUpdate@TN1GG2":32,"gxCcrsUpdate@TN2GG2":525,"gxCcrsUpdate@TN2VEPG1":1376,"gxQosRequests@SO1GG2":46,"gxQosRequests@TN1GG2":0,"gxQosRequests@TN2GG2":43,"gxQosRequests@TN2VEPG1":49,"gxRaas@SO1GG2":35,"gxRaas@TN1GG2":4,"gxRaas@TN2GG2":14,"gxRaas@TN2VEPG1":10,"gxRaasSuccess@SO1GG2":172179,"gxRaasSuccess@TN1GG2":92,"gxRaasSuccess@TN2GG2":0,"gxRaasSuccess@TN2VEPG1":0,"gxRars@SO1GG2":155,"gxRars@TN1GG2":166,"gxRars@TN2GG2":4,"gxRars@TN2VEPG1":3,"mobileActiveSessions":3,"restGet":2,"rxAaasInitSuccess@rx.so1sbg-pmp1":1,"rxAaasInitSuccess@rx.so1sbg-pmp3":4,"rxAaasInitSuccess@rx.tn2sbg-pmp1":4,"rxAaasSuccess@rx.so1sbg-pmp1":1,"rxAaasSuccess@rx.so1sbg-pmp3":2,"rxAaasSuccess@rx.tn2sbg-pmp1":3,"rxAarsInit@rx.so1sbg-pmp1":3,"rxAarsInit@rx.so1sbg-pmp3":3,"rxAarsInit@rx.tn2sbg-pmp1":0,"rxAarsUpdate@rx.so1sbg-pmp3":2,"rxStasSuccess@rx.so1sbg-pmp1":2,"rxStasSuccess@rx.so1sbg-pmp3":3,"rxStasSuccess@rx.tn2sbg-pmp1":0,"rxStrs@rx.so1sbg-pmp1":3,"rxStrs@rx.so1sbg-pmp3":0,"rxStrs@rx.tn2sbg-pmp1":0,"sdActiveSessions":3,"smfActiveSessions":1,"smpActiveGlobalSessions":3,"subscribers":2}

	org.elasticsearch.hadoop.rest.EsHadoopRemoteException: index_not_found_exception: no such index [spark_data]
	{"index":{}}
{"TimeStamp":2713274100000,"afActiveSessions":3,"afSignallingActiveSessions":2,"amfActiveSessions":1,"fixedActiveSessions":1,"gxCcasInitSuccess@SO1GG2":1466,"gxCcasInitSuccess@TN1GG2":401,"gxCcasInitSuccess@TN2GG2":6,"gxCcasInitSuccess@TN2VEPG1":407,"gxCcasTerminateSuccess@SO1GG2":1435,"gxCcasTerminateSuccess@TN1GG2":1826,"gxCcasTerminateSuccess@TN2GG2":1370,"gxCcasTerminateSuccess@TN2VEPG1":1558,"gxCcasUpdateSuccess@SO1GG2":140667,"gxCcasUpdateSuccess@TN1GG2":1549,"gxCcasUpdateSuccess@TN2GG2":58472,"gxCcasUpdateSuccess@TN2VEPG1":52724,"gxCcrsInit@SO1GG2":1190,"gxCcrsInit@TN1GG2":326,"gxCcrsInit@TN2GG2":570,"gxCcrsInit@TN2VEPG1":947,"gxCcrsTerminate@SO1GG2":808,"gxCcrsTerminate@TN1GG2":1651,"gxCcrsTerminate@TN2GG2":1126,"gxCcrsTerminate@TN2VEPG1":1059,"gxCcrsUpdate@SO1GG2":965,"gxCcrsUpdate@TN1GG2":1102,"gxCcrsUpdate@TN2GG2":180,"gxCcrsUpdate@TN2VEPG1":1773,"gxQosRequests@SO1GG2":38,"gxQosRequests@TN1GG2":8,"gxQosRequests@TN2GG2":48,"gxQosRequests@TN2VEPG1":32,"gxRaas@SO1GG2":37,"gxRaas@TN1GG2":8,"gxRaas@TN2GG2":48,"gxRaas@TN2VEPG1":34,"gxRaasSuccess@SO1GG2":172525,"gxRaasSuccess@TN1GG2":98,"gxRaasSuccess@TN2GG2":0,"gxRaasSuccess@TN2VEPG1":0,"gxRars@SO1GG2":179,"gxRars@TN1GG2":171,"gxRars@TN2GG2":2,"gxRars@TN2VEPG1":4,"mobileActiveSessions":3,"restGet":1,"rxAaasInitSuccess@rx.so1sbg-pmp1":1,"rxAaasInitSuccess@rx.so1sbg-pmp3":0,"rxAaasInitSuccess@rx.tn2sbg-pmp1":3,"rxAaasSuccess@rx.so1sbg-pmp1":3,"rxAaasSuccess@rx.so1sbg-pmp3":1,"rxAaasSuccess@rx.tn2sbg-pmp1":2,"rxAarsInit@rx.so1sbg-pmp1":2,"rxAarsInit@rx.so1sbg-pmp3":1,"rxAarsInit@rx.tn2sbg-pmp1":3,"rxAarsUpdate@rx.so1sbg-pmp3":2,"rxStasSuccess@rx.so1sbg-pmp1":3,"rxStasSuccess@rx.so1sbg-pmp3":1,"rxStasSuccess@rx.tn2sbg-pmp1":0,"rxStrs@rx.so1sbg-pmp1":4,"rxStrs@rx.so1sbg-pmp3":3,"rxStrs@rx.tn2sbg-pmp1":0,"sdActiveSessions":0,"smfActiveSessions":4,"smpActiveGlobalSessions":3,"subscribers":0}

Bailing out...
	org.elasticsearch.hadoop.rest.bulk.BulkProcessor.flush(BulkProcessor.java:538)
	org.elasticsearch.hadoop.rest.bulk.BulkProcessor.add(BulkProcessor.java:132)
	org.elasticsearch.hadoop.rest.RestRepository.doWriteToIndex(RestRepository.java:192)
	org.elasticsearch.hadoop.rest.RestRepository.writeToIndex(RestRepository.java:172)
	org.elasticsearch.spark.rdd.EsRDDWriter.write(EsRDDWriter.scala:83)
	org.elasticsearch.spark.sql.EsSparkSQL$.$anonfun$saveToEs$1(EsSparkSQL.scala:103)
	org.elasticsearch.spark.sql.EsSparkSQL$.$anonfun$saveToEs$1$adapted(EsSparkSQL.scala:103)
	org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)
	org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)
	org.apache.spark.scheduler.Task.run(Task.scala:141)
	org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)
	org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)
	org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)
	org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)
	org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)
	java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	java.base/java.lang.Thread.run(Thread.java:829)
		at org.apache.spark.TaskContextImpl.invokeListeners(TaskContextImpl.scala:254)
		at org.apache.spark.TaskContextImpl.invokeTaskCompletionListeners(TaskContextImpl.scala:144)
		at org.apache.spark.TaskContextImpl.markTaskCompleted(TaskContextImpl.scala:137)
		at org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:172)
		... 9 more
		Suppressed: org.elasticsearch.hadoop.rest.EsHadoopInvalidRequest: org.elasticsearch.hadoop.rest.EsHadoopRemoteException: index_not_found_exception: no such index [spark_data]
null
			at org.elasticsearch.hadoop.rest.RestClient.checkResponse(RestClient.java:487)
			at org.elasticsearch.hadoop.rest.RestClient.execute(RestClient.java:444)
			at org.elasticsearch.hadoop.rest.RestClient.execute(RestClient.java:438)
			at org.elasticsearch.hadoop.rest.RestClient.execute(RestClient.java:398)
			at org.elasticsearch.hadoop.rest.RestClient.execute(RestClient.java:402)
			at org.elasticsearch.hadoop.rest.RestClient.refresh(RestClient.java:285)
			at org.elasticsearch.hadoop.rest.bulk.BulkProcessor.close(BulkProcessor.java:569)
			at org.elasticsearch.hadoop.rest.RestRepository.close(RestRepository.java:226)
			at org.elasticsearch.hadoop.rest.RestService$PartitionWriter.close(RestService.java:122)
			at org.elasticsearch.spark.rdd.EsRDDWriter$$anon$1.onTaskCompletion(EsRDDWriter.scala:74)
			at org.apache.spark.TaskContextImpl.$anonfun$invokeTaskCompletionListeners$1(TaskContextImpl.scala:144)
			at org.apache.spark.TaskContextImpl.$anonfun$invokeTaskCompletionListeners$1$adapted(TaskContextImpl.scala:144)
			at org.apache.spark.TaskContextImpl.invokeListeners(TaskContextImpl.scala:199)
			... 12 more

Driver stacktrace:
	at org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2844)
	at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2780)
	at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2779)
	at scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)
	at scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)
	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2779)
	at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1242)
	at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1242)
	at scala.Option.foreach(Option.scala:407)
	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1242)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:3048)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2982)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2971)
	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)
	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:984)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2398)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2419)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2451)
	at org.elasticsearch.spark.sql.EsSparkSQL$.saveToEs(EsSparkSQL.scala:103)
	at org.elasticsearch.spark.sql.ElasticsearchRelation.insert(DefaultSource.scala:629)
	at org.elasticsearch.spark.sql.DefaultSource.createRelation(DefaultSource.scala:107)
	at org.apache.spark.sql.execution.datasources.SaveIntoDataSourceCommand.run(SaveIntoDataSourceCommand.scala:48)
	at org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult$lzycompute(commands.scala:75)
	at org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult(commands.scala:73)
	at org.apache.spark.sql.execution.command.ExecutedCommandExec.executeCollect(commands.scala:84)
	at org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.$anonfun$applyOrElse$1(QueryExecution.scala:107)
	at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)
	at org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)
	at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)
	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
	at org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)
	at org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:107)
	at org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:98)
	at org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:461)
	at org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)
	at org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:461)
	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:32)
	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:267)
	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:263)
	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)
	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)
	at org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:437)
	at org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:98)
	at org.apache.spark.sql.execution.QueryExecution.commandExecuted$lzycompute(QueryExecution.scala:85)
	at org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:83)
	at org.apache.spark.sql.execution.QueryExecution.assertCommandExecuted(QueryExecution.scala:142)
	at org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:859)
	at org.apache.spark.sql.DataFrameWriter.saveToV1Source(DataFrameWriter.scala:388)
	at org.apache.spark.sql.DataFrameWriter.saveInternal(DataFrameWriter.scala:361)
	at org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:248)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)
	at py4j.Gateway.invoke(Gateway.java:282)
	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
	at py4j.commands.CallCommand.execute(CallCommand.java:79)
	at py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)
	at py4j.ClientServerConnection.run(ClientServerConnection.java:106)
	at java.base/java.lang.Thread.run(Thread.java:829)
Caused by: org.elasticsearch.hadoop.EsHadoopException: Could not write all entries for bulk operation [556/556]. Error sample (first [5] error messages):
	org.elasticsearch.hadoop.rest.EsHadoopRemoteException: index_not_found_exception: no such index [spark_data]
	{"index":{}}
{"TimeStamp":2713263300000,"afActiveSessions":0,"afSignallingActiveSessions":2,"amfActiveSessions":7,"fixedActiveSessions":1,"gxCcasInitSuccess@SO1GG2":149,"gxCcasInitSuccess@TN1GG2":1351,"gxCcasInitSuccess@TN2GG2":1073,"gxCcasInitSuccess@TN2VEPG1":1770,"gxCcasTerminateSuccess@SO1GG2":310,"gxCcasTerminateSuccess@TN1GG2":1930,"gxCcasTerminateSuccess@TN2GG2":1111,"gxCcasTerminateSuccess@TN2VEPG1":1072,"gxCcasUpdateSuccess@SO1GG2":154134,"gxCcasUpdateSuccess@TN1GG2":1250,"gxCcasUpdateSuccess@TN2GG2":55571,"gxCcasUpdateSuccess@TN2VEPG1":66934,"gxCcrsInit@SO1GG2":97,"gxCcrsInit@TN1GG2":179,"gxCcrsInit@TN2GG2":732,"gxCcrsInit@TN2VEPG1":1626,"gxCcrsTerminate@SO1GG2":104,"gxCcrsTerminate@TN1GG2":1061,"gxCcrsTerminate@TN2GG2":1637,"gxCcrsTerminate@TN2VEPG1":1569,"gxCcrsUpdate@SO1GG2":1317,"gxCcrsUpdate@TN1GG2":383,"gxCcrsUpdate@TN2GG2":1467,"gxCcrsUpdate@TN2VEPG1":316,"gxQosRequests@SO1GG2":35,"gxQosRequests@TN1GG2":7,"gxQosRequests@TN2GG2":11,"gxQosRequests@TN2VEPG1":48,"gxRaas@SO1GG2":48,"gxRaas@TN1GG2":6,"gxRaas@TN2GG2":34,"gxRaas@TN2VEPG1":26,"gxRaasSuccess@SO1GG2":176101,"gxRaasSuccess@TN1GG2":52,"gxRaasSuccess@TN2GG2":1,"gxRaasSuccess@TN2VEPG1":0,"gxRars@SO1GG2":186,"gxRars@TN1GG2":189,"gxRars@TN2GG2":4,"gxRars@TN2VEPG1":0,"mobileActiveSessions":0,"restGet":1,"rxAaasInitSuccess@rx.so1sbg-pmp1":0,"rxAaasInitSuccess@rx.so1sbg-pmp3":4,"rxAaasInitSuccess@rx.tn2sbg-pmp1":4,"rxAaasSuccess@rx.so1sbg-pmp1":3,"rxAaasSuccess@rx.so1sbg-pmp3":1,"rxAaasSuccess@rx.tn2sbg-pmp1":4,"rxAarsInit@rx.so1sbg-pmp1":3,"rxAarsInit@rx.so1sbg-pmp3":3,"rxAarsInit@rx.tn2sbg-pmp1":3,"rxAarsUpdate@rx.so1sbg-pmp3":3,"rxStasSuccess@rx.so1sbg-pmp1":2,"rxStasSuccess@rx.so1sbg-pmp3":2,"rxStasSuccess@rx.tn2sbg-pmp1":1,"rxStrs@rx.so1sbg-pmp1":3,"rxStrs@rx.so1sbg-pmp3":4,"rxStrs@rx.tn2sbg-pmp1":2,"sdActiveSessions":0,"smfActiveSessions":4,"smpActiveGlobalSessions":4,"subscribers":1}

	org.elasticsearch.hadoop.rest.EsHadoopRemoteException: index_not_found_exception: no such index [spark_data]
	{"index":{}}
{"TimeStamp":2713264200000,"afActiveSessions":3,"afSignallingActiveSessions":1,"amfActiveSessions":7,"fixedActiveSessions":2,"gxCcasInitSuccess@SO1GG2":1501,"gxCcasInitSuccess@TN1GG2":1261,"gxCcasInitSuccess@TN2GG2":603,"gxCcasInitSuccess@TN2VEPG1":1244,"gxCcasTerminateSuccess@SO1GG2":1508,"gxCcasTerminateSuccess@TN1GG2":392,"gxCcasTerminateSuccess@TN2GG2":1846,"gxCcasTerminateSuccess@TN2VEPG1":1299,"gxCcasUpdateSuccess@SO1GG2":199342,"gxCcasUpdateSuccess@TN1GG2":1039,"gxCcasUpdateSuccess@TN2GG2":60368,"gxCcasUpdateSuccess@TN2VEPG1":63113,"gxCcrsInit@SO1GG2":992,"gxCcrsInit@TN1GG2":542,"gxCcrsInit@TN2GG2":198,"gxCcrsInit@TN2VEPG1":797,"gxCcrsTerminate@SO1GG2":1216,"gxCcrsTerminate@TN1GG2":16,"gxCcrsTerminate@TN2GG2":1883,"gxCcrsTerminate@TN2VEPG1":1971,"gxCcrsUpdate@SO1GG2":37,"gxCcrsUpdate@TN1GG2":24,"gxCcrsUpdate@TN2GG2":1579,"gxCcrsUpdate@TN2VEPG1":1157,"gxQosRequests@SO1GG2":34,"gxQosRequests@TN1GG2":7,"gxQosRequests@TN2GG2":18,"gxQosRequests@TN2VEPG1":39,"gxRaas@SO1GG2":35,"gxRaas@TN1GG2":4,"gxRaas@TN2GG2":36,"gxRaas@TN2VEPG1":42,"gxRaasSuccess@SO1GG2":171924,"gxRaasSuccess@TN1GG2":88,"gxRaasSuccess@TN2GG2":1,"gxRaasSuccess@TN2VEPG1":1,"gxRars@SO1GG2":193,"gxRars@TN1GG2":170,"gxRars@TN2GG2":1,"gxRars@TN2VEPG1":2,"mobileActiveSessions":2,"restGet":2,"rxAaasInitSuccess@rx.so1sbg-pmp1":0,"rxAaasInitSuccess@rx.so1sbg-pmp3":3,"rxAaasInitSuccess@rx.tn2sbg-pmp1":0,"rxAaasSuccess@rx.so1sbg-pmp1":0,"rxAaasSuccess@rx.so1sbg-pmp3":3,"rxAaasSuccess@rx.tn2sbg-pmp1":0,"rxAarsInit@rx.so1sbg-pmp1":3,"rxAarsInit@rx.so1sbg-pmp3":2,"rxAarsInit@rx.tn2sbg-pmp1":2,"rxAarsUpdate@rx.so1sbg-pmp3":4,"rxStasSuccess@rx.so1sbg-pmp1":3,"rxStasSuccess@rx.so1sbg-pmp3":0,"rxStasSuccess@rx.tn2sbg-pmp1":2,"rxStrs@rx.so1sbg-pmp1":3,"rxStrs@rx.so1sbg-pmp3":0,"rxStrs@rx.tn2sbg-pmp1":2,"sdActiveSessions":2,"smfActiveSessions":3,"smpActiveGlobalSessions":1,"subscribers":3}

	org.elasticsearch.hadoop.rest.EsHadoopRemoteException: index_not_found_exception: no such index [spark_data]
	{"index":{}}
{"TimeStamp":2713266900000,"afActiveSessions":7,"afSignallingActiveSessions":1,"amfActiveSessions":2,"fixedActiveSessions":4,"gxCcasInitSuccess@SO1GG2":1378,"gxCcasInitSuccess@TN1GG2":1809,"gxCcasInitSuccess@TN2GG2":465,"gxCcasInitSuccess@TN2VEPG1":1390,"gxCcasTerminateSuccess@SO1GG2":383,"gxCcasTerminateSuccess@TN1GG2":1297,"gxCcasTerminateSuccess@TN2GG2":827,"gxCcasTerminateSuccess@TN2VEPG1":770,"gxCcasUpdateSuccess@SO1GG2":189110,"gxCcasUpdateSuccess@TN1GG2":1409,"gxCcasUpdateSuccess@TN2GG2":68332,"gxCcasUpdateSuccess@TN2VEPG1":59842,"gxCcrsInit@SO1GG2":1872,"gxCcrsInit@TN1GG2":1727,"gxCcrsInit@TN2GG2":866,"gxCcrsInit@TN2VEPG1":1104,"gxCcrsTerminate@SO1GG2":397,"gxCcrsTerminate@TN1GG2":277,"gxCcrsTerminate@TN2GG2":1072,"gxCcrsTerminate@TN2VEPG1":733,"gxCcrsUpdate@SO1GG2":1124,"gxCcrsUpdate@TN1GG2":1405,"gxCcrsUpdate@TN2GG2":1678,"gxCcrsUpdate@TN2VEPG1":671,"gxQosRequests@SO1GG2":39,"gxQosRequests@TN1GG2":5,"gxQosRequests@TN2GG2":41,"gxQosRequests@TN2VEPG1":25,"gxRaas@SO1GG2":41,"gxRaas@TN1GG2":1,"gxRaas@TN2GG2":32,"gxRaas@TN2VEPG1":44,"gxRaasSuccess@SO1GG2":173342,"gxRaasSuccess@TN1GG2":73,"gxRaasSuccess@TN2GG2":1,"gxRaasSuccess@TN2VEPG1":0,"gxRars@SO1GG2":170,"gxRars@TN1GG2":155,"gxRars@TN2GG2":3,"gxRars@TN2VEPG1":0,"mobileActiveSessions":3,"restGet":1,"rxAaasInitSuccess@rx.so1sbg-pmp1":0,"rxAaasInitSuccess@rx.so1sbg-pmp3":4,"rxAaasInitSuccess@rx.tn2sbg-pmp1":3,"rxAaasSuccess@rx.so1sbg-pmp1":2,"rxAaasSuccess@rx.so1sbg-pmp3":3,"rxAaasSuccess@rx.tn2sbg-pmp1":4,"rxAarsInit@rx.so1sbg-pmp1":1,"rxAarsInit@rx.so1sbg-pmp3":4,"rxAarsInit@rx.tn2sbg-pmp1":2,"rxAarsUpdate@rx.so1sbg-pmp3":4,"rxStasSuccess@rx.so1sbg-pmp1":1,"rxStasSuccess@rx.so1sbg-pmp3":4,"rxStasSuccess@rx.tn2sbg-pmp1":2,"rxStrs@rx.so1sbg-pmp1":1,"rxStrs@rx.so1sbg-pmp3":1,"rxStrs@rx.tn2sbg-pmp1":2,"sdActiveSessions":1,"smfActiveSessions":3,"smpActiveGlobalSessions":1,"subscribers":2}

	org.elasticsearch.hadoop.rest.EsHadoopRemoteException: index_not_found_exception: no such index [spark_data]
	{"index":{}}
{"TimeStamp":2713269600000,"afActiveSessions":7,"afSignallingActiveSessions":4,"amfActiveSessions":7,"fixedActiveSessions":4,"gxCcasInitSuccess@SO1GG2":642,"gxCcasInitSuccess@TN1GG2":615,"gxCcasInitSuccess@TN2GG2":1432,"gxCcasInitSuccess@TN2VEPG1":1807,"gxCcasTerminateSuccess@SO1GG2":58,"gxCcasTerminateSuccess@TN1GG2":411,"gxCcasTerminateSuccess@TN2GG2":1738,"gxCcasTerminateSuccess@TN2VEPG1":226,"gxCcasUpdateSuccess@SO1GG2":138256,"gxCcasUpdateSuccess@TN1GG2":1367,"gxCcasUpdateSuccess@TN2GG2":51792,"gxCcasUpdateSuccess@TN2VEPG1":62513,"gxCcrsInit@SO1GG2":401,"gxCcrsInit@TN1GG2":777,"gxCcrsInit@TN2GG2":1662,"gxCcrsInit@TN2VEPG1":1289,"gxCcrsTerminate@SO1GG2":1660,"gxCcrsTerminate@TN1GG2":1926,"gxCcrsTerminate@TN2GG2":379,"gxCcrsTerminate@TN2VEPG1":267,"gxCcrsUpdate@SO1GG2":802,"gxCcrsUpdate@TN1GG2":32,"gxCcrsUpdate@TN2GG2":525,"gxCcrsUpdate@TN2VEPG1":1376,"gxQosRequests@SO1GG2":46,"gxQosRequests@TN1GG2":0,"gxQosRequests@TN2GG2":43,"gxQosRequests@TN2VEPG1":49,"gxRaas@SO1GG2":35,"gxRaas@TN1GG2":4,"gxRaas@TN2GG2":14,"gxRaas@TN2VEPG1":10,"gxRaasSuccess@SO1GG2":172179,"gxRaasSuccess@TN1GG2":92,"gxRaasSuccess@TN2GG2":0,"gxRaasSuccess@TN2VEPG1":0,"gxRars@SO1GG2":155,"gxRars@TN1GG2":166,"gxRars@TN2GG2":4,"gxRars@TN2VEPG1":3,"mobileActiveSessions":3,"restGet":2,"rxAaasInitSuccess@rx.so1sbg-pmp1":1,"rxAaasInitSuccess@rx.so1sbg-pmp3":4,"rxAaasInitSuccess@rx.tn2sbg-pmp1":4,"rxAaasSuccess@rx.so1sbg-pmp1":1,"rxAaasSuccess@rx.so1sbg-pmp3":2,"rxAaasSuccess@rx.tn2sbg-pmp1":3,"rxAarsInit@rx.so1sbg-pmp1":3,"rxAarsInit@rx.so1sbg-pmp3":3,"rxAarsInit@rx.tn2sbg-pmp1":0,"rxAarsUpdate@rx.so1sbg-pmp3":2,"rxStasSuccess@rx.so1sbg-pmp1":2,"rxStasSuccess@rx.so1sbg-pmp3":3,"rxStasSuccess@rx.tn2sbg-pmp1":0,"rxStrs@rx.so1sbg-pmp1":3,"rxStrs@rx.so1sbg-pmp3":0,"rxStrs@rx.tn2sbg-pmp1":0,"sdActiveSessions":3,"smfActiveSessions":1,"smpActiveGlobalSessions":3,"subscribers":2}

	org.elasticsearch.hadoop.rest.EsHadoopRemoteException: index_not_found_exception: no such index [spark_data]
	{"index":{}}
{"TimeStamp":2713274100000,"afActiveSessions":3,"afSignallingActiveSessions":2,"amfActiveSessions":1,"fixedActiveSessions":1,"gxCcasInitSuccess@SO1GG2":1466,"gxCcasInitSuccess@TN1GG2":401,"gxCcasInitSuccess@TN2GG2":6,"gxCcasInitSuccess@TN2VEPG1":407,"gxCcasTerminateSuccess@SO1GG2":1435,"gxCcasTerminateSuccess@TN1GG2":1826,"gxCcasTerminateSuccess@TN2GG2":1370,"gxCcasTerminateSuccess@TN2VEPG1":1558,"gxCcasUpdateSuccess@SO1GG2":140667,"gxCcasUpdateSuccess@TN1GG2":1549,"gxCcasUpdateSuccess@TN2GG2":58472,"gxCcasUpdateSuccess@TN2VEPG1":52724,"gxCcrsInit@SO1GG2":1190,"gxCcrsInit@TN1GG2":326,"gxCcrsInit@TN2GG2":570,"gxCcrsInit@TN2VEPG1":947,"gxCcrsTerminate@SO1GG2":808,"gxCcrsTerminate@TN1GG2":1651,"gxCcrsTerminate@TN2GG2":1126,"gxCcrsTerminate@TN2VEPG1":1059,"gxCcrsUpdate@SO1GG2":965,"gxCcrsUpdate@TN1GG2":1102,"gxCcrsUpdate@TN2GG2":180,"gxCcrsUpdate@TN2VEPG1":1773,"gxQosRequests@SO1GG2":38,"gxQosRequests@TN1GG2":8,"gxQosRequests@TN2GG2":48,"gxQosRequests@TN2VEPG1":32,"gxRaas@SO1GG2":37,"gxRaas@TN1GG2":8,"gxRaas@TN2GG2":48,"gxRaas@TN2VEPG1":34,"gxRaasSuccess@SO1GG2":172525,"gxRaasSuccess@TN1GG2":98,"gxRaasSuccess@TN2GG2":0,"gxRaasSuccess@TN2VEPG1":0,"gxRars@SO1GG2":179,"gxRars@TN1GG2":171,"gxRars@TN2GG2":2,"gxRars@TN2VEPG1":4,"mobileActiveSessions":3,"restGet":1,"rxAaasInitSuccess@rx.so1sbg-pmp1":1,"rxAaasInitSuccess@rx.so1sbg-pmp3":0,"rxAaasInitSuccess@rx.tn2sbg-pmp1":3,"rxAaasSuccess@rx.so1sbg-pmp1":3,"rxAaasSuccess@rx.so1sbg-pmp3":1,"rxAaasSuccess@rx.tn2sbg-pmp1":2,"rxAarsInit@rx.so1sbg-pmp1":2,"rxAarsInit@rx.so1sbg-pmp3":1,"rxAarsInit@rx.tn2sbg-pmp1":3,"rxAarsUpdate@rx.so1sbg-pmp3":2,"rxStasSuccess@rx.so1sbg-pmp1":3,"rxStasSuccess@rx.so1sbg-pmp3":1,"rxStasSuccess@rx.tn2sbg-pmp1":0,"rxStrs@rx.so1sbg-pmp1":4,"rxStrs@rx.so1sbg-pmp3":3,"rxStrs@rx.tn2sbg-pmp1":0,"sdActiveSessions":0,"smfActiveSessions":4,"smpActiveGlobalSessions":3,"subscribers":0}

Bailing out...
	at org.elasticsearch.hadoop.rest.bulk.BulkProcessor.flush(BulkProcessor.java:538)
	at org.elasticsearch.hadoop.rest.bulk.BulkProcessor.add(BulkProcessor.java:132)
	at org.elasticsearch.hadoop.rest.RestRepository.doWriteToIndex(RestRepository.java:192)
	at org.elasticsearch.hadoop.rest.RestRepository.writeToIndex(RestRepository.java:172)
	at org.elasticsearch.spark.rdd.EsRDDWriter.write(EsRDDWriter.scala:83)
	at org.elasticsearch.spark.sql.EsSparkSQL$.$anonfun$saveToEs$1(EsSparkSQL.scala:103)
	at org.elasticsearch.spark.sql.EsSparkSQL$.$anonfun$saveToEs$1$adapted(EsSparkSQL.scala:103)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)
	at org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)
	at org.apache.spark.scheduler.Task.run(Task.scala:141)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	... 1 more
	Suppressed: org.apache.spark.util.TaskCompletionListenerException: org.elasticsearch.hadoop.rest.EsHadoopRemoteException: index_not_found_exception: no such index [spark_data]
null

Previous exception in task: Could not write all entries for bulk operation [556/556]. Error sample (first [5] error messages):
	org.elasticsearch.hadoop.rest.EsHadoopRemoteException: index_not_found_exception: no such index [spark_data]
	{"index":{}}
{"TimeStamp":2713263300000,"afActiveSessions":0,"afSignallingActiveSessions":2,"amfActiveSessions":7,"fixedActiveSessions":1,"gxCcasInitSuccess@SO1GG2":149,"gxCcasInitSuccess@TN1GG2":1351,"gxCcasInitSuccess@TN2GG2":1073,"gxCcasInitSuccess@TN2VEPG1":1770,"gxCcasTerminateSuccess@SO1GG2":310,"gxCcasTerminateSuccess@TN1GG2":1930,"gxCcasTerminateSuccess@TN2GG2":1111,"gxCcasTerminateSuccess@TN2VEPG1":1072,"gxCcasUpdateSuccess@SO1GG2":154134,"gxCcasUpdateSuccess@TN1GG2":1250,"gxCcasUpdateSuccess@TN2GG2":55571,"gxCcasUpdateSuccess@TN2VEPG1":66934,"gxCcrsInit@SO1GG2":97,"gxCcrsInit@TN1GG2":179,"gxCcrsInit@TN2GG2":732,"gxCcrsInit@TN2VEPG1":1626,"gxCcrsTerminate@SO1GG2":104,"gxCcrsTerminate@TN1GG2":1061,"gxCcrsTerminate@TN2GG2":1637,"gxCcrsTerminate@TN2VEPG1":1569,"gxCcrsUpdate@SO1GG2":1317,"gxCcrsUpdate@TN1GG2":383,"gxCcrsUpdate@TN2GG2":1467,"gxCcrsUpdate@TN2VEPG1":316,"gxQosRequests@SO1GG2":35,"gxQosRequests@TN1GG2":7,"gxQosRequests@TN2GG2":11,"gxQosRequests@TN2VEPG1":48,"gxRaas@SO1GG2":48,"gxRaas@TN1GG2":6,"gxRaas@TN2GG2":34,"gxRaas@TN2VEPG1":26,"gxRaasSuccess@SO1GG2":176101,"gxRaasSuccess@TN1GG2":52,"gxRaasSuccess@TN2GG2":1,"gxRaasSuccess@TN2VEPG1":0,"gxRars@SO1GG2":186,"gxRars@TN1GG2":189,"gxRars@TN2GG2":4,"gxRars@TN2VEPG1":0,"mobileActiveSessions":0,"restGet":1,"rxAaasInitSuccess@rx.so1sbg-pmp1":0,"rxAaasInitSuccess@rx.so1sbg-pmp3":4,"rxAaasInitSuccess@rx.tn2sbg-pmp1":4,"rxAaasSuccess@rx.so1sbg-pmp1":3,"rxAaasSuccess@rx.so1sbg-pmp3":1,"rxAaasSuccess@rx.tn2sbg-pmp1":4,"rxAarsInit@rx.so1sbg-pmp1":3,"rxAarsInit@rx.so1sbg-pmp3":3,"rxAarsInit@rx.tn2sbg-pmp1":3,"rxAarsUpdate@rx.so1sbg-pmp3":3,"rxStasSuccess@rx.so1sbg-pmp1":2,"rxStasSuccess@rx.so1sbg-pmp3":2,"rxStasSuccess@rx.tn2sbg-pmp1":1,"rxStrs@rx.so1sbg-pmp1":3,"rxStrs@rx.so1sbg-pmp3":4,"rxStrs@rx.tn2sbg-pmp1":2,"sdActiveSessions":0,"smfActiveSessions":4,"smpActiveGlobalSessions":4,"subscribers":1}

	org.elasticsearch.hadoop.rest.EsHadoopRemoteException: index_not_found_exception: no such index [spark_data]
	{"index":{}}
{"TimeStamp":2713264200000,"afActiveSessions":3,"afSignallingActiveSessions":1,"amfActiveSessions":7,"fixedActiveSessions":2,"gxCcasInitSuccess@SO1GG2":1501,"gxCcasInitSuccess@TN1GG2":1261,"gxCcasInitSuccess@TN2GG2":603,"gxCcasInitSuccess@TN2VEPG1":1244,"gxCcasTerminateSuccess@SO1GG2":1508,"gxCcasTerminateSuccess@TN1GG2":392,"gxCcasTerminateSuccess@TN2GG2":1846,"gxCcasTerminateSuccess@TN2VEPG1":1299,"gxCcasUpdateSuccess@SO1GG2":199342,"gxCcasUpdateSuccess@TN1GG2":1039,"gxCcasUpdateSuccess@TN2GG2":60368,"gxCcasUpdateSuccess@TN2VEPG1":63113,"gxCcrsInit@SO1GG2":992,"gxCcrsInit@TN1GG2":542,"gxCcrsInit@TN2GG2":198,"gxCcrsInit@TN2VEPG1":797,"gxCcrsTerminate@SO1GG2":1216,"gxCcrsTerminate@TN1GG2":16,"gxCcrsTerminate@TN2GG2":1883,"gxCcrsTerminate@TN2VEPG1":1971,"gxCcrsUpdate@SO1GG2":37,"gxCcrsUpdate@TN1GG2":24,"gxCcrsUpdate@TN2GG2":1579,"gxCcrsUpdate@TN2VEPG1":1157,"gxQosRequests@SO1GG2":34,"gxQosRequests@TN1GG2":7,"gxQosRequests@TN2GG2":18,"gxQosRequests@TN2VEPG1":39,"gxRaas@SO1GG2":35,"gxRaas@TN1GG2":4,"gxRaas@TN2GG2":36,"gxRaas@TN2VEPG1":42,"gxRaasSuccess@SO1GG2":171924,"gxRaasSuccess@TN1GG2":88,"gxRaasSuccess@TN2GG2":1,"gxRaasSuccess@TN2VEPG1":1,"gxRars@SO1GG2":193,"gxRars@TN1GG2":170,"gxRars@TN2GG2":1,"gxRars@TN2VEPG1":2,"mobileActiveSessions":2,"restGet":2,"rxAaasInitSuccess@rx.so1sbg-pmp1":0,"rxAaasInitSuccess@rx.so1sbg-pmp3":3,"rxAaasInitSuccess@rx.tn2sbg-pmp1":0,"rxAaasSuccess@rx.so1sbg-pmp1":0,"rxAaasSuccess@rx.so1sbg-pmp3":3,"rxAaasSuccess@rx.tn2sbg-pmp1":0,"rxAarsInit@rx.so1sbg-pmp1":3,"rxAarsInit@rx.so1sbg-pmp3":2,"rxAarsInit@rx.tn2sbg-pmp1":2,"rxAarsUpdate@rx.so1sbg-pmp3":4,"rxStasSuccess@rx.so1sbg-pmp1":3,"rxStasSuccess@rx.so1sbg-pmp3":0,"rxStasSuccess@rx.tn2sbg-pmp1":2,"rxStrs@rx.so1sbg-pmp1":3,"rxStrs@rx.so1sbg-pmp3":0,"rxStrs@rx.tn2sbg-pmp1":2,"sdActiveSessions":2,"smfActiveSessions":3,"smpActiveGlobalSessions":1,"subscribers":3}

	org.elasticsearch.hadoop.rest.EsHadoopRemoteException: index_not_found_exception: no such index [spark_data]
	{"index":{}}
{"TimeStamp":2713266900000,"afActiveSessions":7,"afSignallingActiveSessions":1,"amfActiveSessions":2,"fixedActiveSessions":4,"gxCcasInitSuccess@SO1GG2":1378,"gxCcasInitSuccess@TN1GG2":1809,"gxCcasInitSuccess@TN2GG2":465,"gxCcasInitSuccess@TN2VEPG1":1390,"gxCcasTerminateSuccess@SO1GG2":383,"gxCcasTerminateSuccess@TN1GG2":1297,"gxCcasTerminateSuccess@TN2GG2":827,"gxCcasTerminateSuccess@TN2VEPG1":770,"gxCcasUpdateSuccess@SO1GG2":189110,"gxCcasUpdateSuccess@TN1GG2":1409,"gxCcasUpdateSuccess@TN2GG2":68332,"gxCcasUpdateSuccess@TN2VEPG1":59842,"gxCcrsInit@SO1GG2":1872,"gxCcrsInit@TN1GG2":1727,"gxCcrsInit@TN2GG2":866,"gxCcrsInit@TN2VEPG1":1104,"gxCcrsTerminate@SO1GG2":397,"gxCcrsTerminate@TN1GG2":277,"gxCcrsTerminate@TN2GG2":1072,"gxCcrsTerminate@TN2VEPG1":733,"gxCcrsUpdate@SO1GG2":1124,"gxCcrsUpdate@TN1GG2":1405,"gxCcrsUpdate@TN2GG2":1678,"gxCcrsUpdate@TN2VEPG1":671,"gxQosRequests@SO1GG2":39,"gxQosRequests@TN1GG2":5,"gxQosRequests@TN2GG2":41,"gxQosRequests@TN2VEPG1":25,"gxRaas@SO1GG2":41,"gxRaas@TN1GG2":1,"gxRaas@TN2GG2":32,"gxRaas@TN2VEPG1":44,"gxRaasSuccess@SO1GG2":173342,"gxRaasSuccess@TN1GG2":73,"gxRaasSuccess@TN2GG2":1,"gxRaasSuccess@TN2VEPG1":0,"gxRars@SO1GG2":170,"gxRars@TN1GG2":155,"gxRars@TN2GG2":3,"gxRars@TN2VEPG1":0,"mobileActiveSessions":3,"restGet":1,"rxAaasInitSuccess@rx.so1sbg-pmp1":0,"rxAaasInitSuccess@rx.so1sbg-pmp3":4,"rxAaasInitSuccess@rx.tn2sbg-pmp1":3,"rxAaasSuccess@rx.so1sbg-pmp1":2,"rxAaasSuccess@rx.so1sbg-pmp3":3,"rxAaasSuccess@rx.tn2sbg-pmp1":4,"rxAarsInit@rx.so1sbg-pmp1":1,"rxAarsInit@rx.so1sbg-pmp3":4,"rxAarsInit@rx.tn2sbg-pmp1":2,"rxAarsUpdate@rx.so1sbg-pmp3":4,"rxStasSuccess@rx.so1sbg-pmp1":1,"rxStasSuccess@rx.so1sbg-pmp3":4,"rxStasSuccess@rx.tn2sbg-pmp1":2,"rxStrs@rx.so1sbg-pmp1":1,"rxStrs@rx.so1sbg-pmp3":1,"rxStrs@rx.tn2sbg-pmp1":2,"sdActiveSessions":1,"smfActiveSessions":3,"smpActiveGlobalSessions":1,"subscribers":2}

	org.elasticsearch.hadoop.rest.EsHadoopRemoteException: index_not_found_exception: no such index [spark_data]
	{"index":{}}
{"TimeStamp":2713269600000,"afActiveSessions":7,"afSignallingActiveSessions":4,"amfActiveSessions":7,"fixedActiveSessions":4,"gxCcasInitSuccess@SO1GG2":642,"gxCcasInitSuccess@TN1GG2":615,"gxCcasInitSuccess@TN2GG2":1432,"gxCcasInitSuccess@TN2VEPG1":1807,"gxCcasTerminateSuccess@SO1GG2":58,"gxCcasTerminateSuccess@TN1GG2":411,"gxCcasTerminateSuccess@TN2GG2":1738,"gxCcasTerminateSuccess@TN2VEPG1":226,"gxCcasUpdateSuccess@SO1GG2":138256,"gxCcasUpdateSuccess@TN1GG2":1367,"gxCcasUpdateSuccess@TN2GG2":51792,"gxCcasUpdateSuccess@TN2VEPG1":62513,"gxCcrsInit@SO1GG2":401,"gxCcrsInit@TN1GG2":777,"gxCcrsInit@TN2GG2":1662,"gxCcrsInit@TN2VEPG1":1289,"gxCcrsTerminate@SO1GG2":1660,"gxCcrsTerminate@TN1GG2":1926,"gxCcrsTerminate@TN2GG2":379,"gxCcrsTerminate@TN2VEPG1":267,"gxCcrsUpdate@SO1GG2":802,"gxCcrsUpdate@TN1GG2":32,"gxCcrsUpdate@TN2GG2":525,"gxCcrsUpdate@TN2VEPG1":1376,"gxQosRequests@SO1GG2":46,"gxQosRequests@TN1GG2":0,"gxQosRequests@TN2GG2":43,"gxQosRequests@TN2VEPG1":49,"gxRaas@SO1GG2":35,"gxRaas@TN1GG2":4,"gxRaas@TN2GG2":14,"gxRaas@TN2VEPG1":10,"gxRaasSuccess@SO1GG2":172179,"gxRaasSuccess@TN1GG2":92,"gxRaasSuccess@TN2GG2":0,"gxRaasSuccess@TN2VEPG1":0,"gxRars@SO1GG2":155,"gxRars@TN1GG2":166,"gxRars@TN2GG2":4,"gxRars@TN2VEPG1":3,"mobileActiveSessions":3,"restGet":2,"rxAaasInitSuccess@rx.so1sbg-pmp1":1,"rxAaasInitSuccess@rx.so1sbg-pmp3":4,"rxAaasInitSuccess@rx.tn2sbg-pmp1":4,"rxAaasSuccess@rx.so1sbg-pmp1":1,"rxAaasSuccess@rx.so1sbg-pmp3":2,"rxAaasSuccess@rx.tn2sbg-pmp1":3,"rxAarsInit@rx.so1sbg-pmp1":3,"rxAarsInit@rx.so1sbg-pmp3":3,"rxAarsInit@rx.tn2sbg-pmp1":0,"rxAarsUpdate@rx.so1sbg-pmp3":2,"rxStasSuccess@rx.so1sbg-pmp1":2,"rxStasSuccess@rx.so1sbg-pmp3":3,"rxStasSuccess@rx.tn2sbg-pmp1":0,"rxStrs@rx.so1sbg-pmp1":3,"rxStrs@rx.so1sbg-pmp3":0,"rxStrs@rx.tn2sbg-pmp1":0,"sdActiveSessions":3,"smfActiveSessions":1,"smpActiveGlobalSessions":3,"subscribers":2}

	org.elasticsearch.hadoop.rest.EsHadoopRemoteException: index_not_found_exception: no such index [spark_data]
	{"index":{}}
{"TimeStamp":2713274100000,"afActiveSessions":3,"afSignallingActiveSessions":2,"amfActiveSessions":1,"fixedActiveSessions":1,"gxCcasInitSuccess@SO1GG2":1466,"gxCcasInitSuccess@TN1GG2":401,"gxCcasInitSuccess@TN2GG2":6,"gxCcasInitSuccess@TN2VEPG1":407,"gxCcasTerminateSuccess@SO1GG2":1435,"gxCcasTerminateSuccess@TN1GG2":1826,"gxCcasTerminateSuccess@TN2GG2":1370,"gxCcasTerminateSuccess@TN2VEPG1":1558,"gxCcasUpdateSuccess@SO1GG2":140667,"gxCcasUpdateSuccess@TN1GG2":1549,"gxCcasUpdateSuccess@TN2GG2":58472,"gxCcasUpdateSuccess@TN2VEPG1":52724,"gxCcrsInit@SO1GG2":1190,"gxCcrsInit@TN1GG2":326,"gxCcrsInit@TN2GG2":570,"gxCcrsInit@TN2VEPG1":947,"gxCcrsTerminate@SO1GG2":808,"gxCcrsTerminate@TN1GG2":1651,"gxCcrsTerminate@TN2GG2":1126,"gxCcrsTerminate@TN2VEPG1":1059,"gxCcrsUpdate@SO1GG2":965,"gxCcrsUpdate@TN1GG2":1102,"gxCcrsUpdate@TN2GG2":180,"gxCcrsUpdate@TN2VEPG1":1773,"gxQosRequests@SO1GG2":38,"gxQosRequests@TN1GG2":8,"gxQosRequests@TN2GG2":48,"gxQosRequests@TN2VEPG1":32,"gxRaas@SO1GG2":37,"gxRaas@TN1GG2":8,"gxRaas@TN2GG2":48,"gxRaas@TN2VEPG1":34,"gxRaasSuccess@SO1GG2":172525,"gxRaasSuccess@TN1GG2":98,"gxRaasSuccess@TN2GG2":0,"gxRaasSuccess@TN2VEPG1":0,"gxRars@SO1GG2":179,"gxRars@TN1GG2":171,"gxRars@TN2GG2":2,"gxRars@TN2VEPG1":4,"mobileActiveSessions":3,"restGet":1,"rxAaasInitSuccess@rx.so1sbg-pmp1":1,"rxAaasInitSuccess@rx.so1sbg-pmp3":0,"rxAaasInitSuccess@rx.tn2sbg-pmp1":3,"rxAaasSuccess@rx.so1sbg-pmp1":3,"rxAaasSuccess@rx.so1sbg-pmp3":1,"rxAaasSuccess@rx.tn2sbg-pmp1":2,"rxAarsInit@rx.so1sbg-pmp1":2,"rxAarsInit@rx.so1sbg-pmp3":1,"rxAarsInit@rx.tn2sbg-pmp1":3,"rxAarsUpdate@rx.so1sbg-pmp3":2,"rxStasSuccess@rx.so1sbg-pmp1":3,"rxStasSuccess@rx.so1sbg-pmp3":1,"rxStasSuccess@rx.tn2sbg-pmp1":0,"rxStrs@rx.so1sbg-pmp1":4,"rxStrs@rx.so1sbg-pmp3":3,"rxStrs@rx.tn2sbg-pmp1":0,"sdActiveSessions":0,"smfActiveSessions":4,"smpActiveGlobalSessions":3,"subscribers":0}

Bailing out...
	org.elasticsearch.hadoop.rest.bulk.BulkProcessor.flush(BulkProcessor.java:538)
	org.elasticsearch.hadoop.rest.bulk.BulkProcessor.add(BulkProcessor.java:132)
	org.elasticsearch.hadoop.rest.RestRepository.doWriteToIndex(RestRepository.java:192)
	org.elasticsearch.hadoop.rest.RestRepository.writeToIndex(RestRepository.java:172)
	org.elasticsearch.spark.rdd.EsRDDWriter.write(EsRDDWriter.scala:83)
	org.elasticsearch.spark.sql.EsSparkSQL$.$anonfun$saveToEs$1(EsSparkSQL.scala:103)
	org.elasticsearch.spark.sql.EsSparkSQL$.$anonfun$saveToEs$1$adapted(EsSparkSQL.scala:103)
	org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)
	org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)
	org.apache.spark.scheduler.Task.run(Task.scala:141)
	org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)
	org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)
	org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)
	org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)
	org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)
	java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	java.base/java.lang.Thread.run(Thread.java:829)
		at org.apache.spark.TaskContextImpl.invokeListeners(TaskContextImpl.scala:254)
		at org.apache.spark.TaskContextImpl.invokeTaskCompletionListeners(TaskContextImpl.scala:144)
		at org.apache.spark.TaskContextImpl.markTaskCompleted(TaskContextImpl.scala:137)
		at org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:172)
		... 9 more
		Suppressed: org.elasticsearch.hadoop.rest.EsHadoopInvalidRequest: org.elasticsearch.hadoop.rest.EsHadoopRemoteException: index_not_found_exception: no such index [spark_data]
null
			at org.elasticsearch.hadoop.rest.RestClient.checkResponse(RestClient.java:487)
			at org.elasticsearch.hadoop.rest.RestClient.execute(RestClient.java:444)
			at org.elasticsearch.hadoop.rest.RestClient.execute(RestClient.java:438)
			at org.elasticsearch.hadoop.rest.RestClient.execute(RestClient.java:398)
			at org.elasticsearch.hadoop.rest.RestClient.execute(RestClient.java:402)
			at org.elasticsearch.hadoop.rest.RestClient.refresh(RestClient.java:285)
			at org.elasticsearch.hadoop.rest.bulk.BulkProcessor.close(BulkProcessor.java:569)
			at org.elasticsearch.hadoop.rest.RestRepository.close(RestRepository.java:226)
			at org.elasticsearch.hadoop.rest.RestService$PartitionWriter.close(RestService.java:122)
			at org.elasticsearch.spark.rdd.EsRDDWriter$$anon$1.onTaskCompletion(EsRDDWriter.scala:74)
			at org.apache.spark.TaskContextImpl.$anonfun$invokeTaskCompletionListeners$1(TaskContextImpl.scala:144)
			at org.apache.spark.TaskContextImpl.$anonfun$invokeTaskCompletionListeners$1$adapted(TaskContextImpl.scala:144)
			at org.apache.spark.TaskContextImpl.invokeListeners(TaskContextImpl.scala:199)
			... 12 more
[2025-04-30T10:25:18.822+0000] {logging_mixin.py:154} INFO - [INFO] Processing file 10/34: /opt/***/data/generated_data_18.csv
[2025-04-30T10:25:28.577+0000] {logging_mixin.py:154} INFO - [INFO] File /opt/***/data/generated_data_18.csv successfully read with 2000000 rows.
[2025-04-30T10:25:28.578+0000] {logging_mixin.py:154} INFO - [INFO] Applying sampling transformation...
[2025-04-30T10:25:29.486+0000] {logging_mixin.py:154} INFO - [INFO] Sampled DataFrame has 600866 rows.
[2025-04-30T10:25:29.487+0000] {logging_mixin.py:154} INFO - [INFO] Writing to Elasticsearch...
[2025-04-30T10:25:30.045+0000] {logging_mixin.py:154} INFO - [ERROR] Failed to process file /opt/***/data/generated_data_18.csv: An error occurred while calling o185.save.
: org.apache.spark.SparkException: Job aborted due to stage failure: Task 8 in stage 89.0 failed 1 times, most recent failure: Lost task 8.0 in stage 89.0 (TID 896) (d9ec160e05b6 executor driver): org.elasticsearch.hadoop.EsHadoopIllegalArgumentException: Cannot determine write shards for [spark_data]; likely its format is incorrect (maybe it contains illegal characters? or all shards failed?)
	at org.elasticsearch.hadoop.util.Assert.isTrue(Assert.java:60)
	at org.elasticsearch.hadoop.rest.RestService.initSingleIndex(RestService.java:689)
	at org.elasticsearch.hadoop.rest.RestService.createWriter(RestService.java:634)
	at org.elasticsearch.spark.rdd.EsRDDWriter.write(EsRDDWriter.scala:71)
	at org.elasticsearch.spark.sql.EsSparkSQL$.$anonfun$saveToEs$1(EsSparkSQL.scala:103)
	at org.elasticsearch.spark.sql.EsSparkSQL$.$anonfun$saveToEs$1$adapted(EsSparkSQL.scala:103)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)
	at org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)
	at org.apache.spark.scheduler.Task.run(Task.scala:141)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:829)

Driver stacktrace:
	at org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2844)
	at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2780)
	at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2779)
	at scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)
	at scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)
	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2779)
	at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1242)
	at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1242)
	at scala.Option.foreach(Option.scala:407)
	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1242)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:3048)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2982)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2971)
	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)
	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:984)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2398)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2419)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2451)
	at org.elasticsearch.spark.sql.EsSparkSQL$.saveToEs(EsSparkSQL.scala:103)
	at org.elasticsearch.spark.sql.ElasticsearchRelation.insert(DefaultSource.scala:629)
	at org.elasticsearch.spark.sql.DefaultSource.createRelation(DefaultSource.scala:107)
	at org.apache.spark.sql.execution.datasources.SaveIntoDataSourceCommand.run(SaveIntoDataSourceCommand.scala:48)
	at org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult$lzycompute(commands.scala:75)
	at org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult(commands.scala:73)
	at org.apache.spark.sql.execution.command.ExecutedCommandExec.executeCollect(commands.scala:84)
	at org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.$anonfun$applyOrElse$1(QueryExecution.scala:107)
	at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)
	at org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)
	at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)
	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
	at org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)
	at org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:107)
	at org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:98)
	at org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:461)
	at org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)
	at org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:461)
	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:32)
	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:267)
	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:263)
	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)
	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)
	at org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:437)
	at org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:98)
	at org.apache.spark.sql.execution.QueryExecution.commandExecuted$lzycompute(QueryExecution.scala:85)
	at org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:83)
	at org.apache.spark.sql.execution.QueryExecution.assertCommandExecuted(QueryExecution.scala:142)
	at org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:859)
	at org.apache.spark.sql.DataFrameWriter.saveToV1Source(DataFrameWriter.scala:388)
	at org.apache.spark.sql.DataFrameWriter.saveInternal(DataFrameWriter.scala:361)
	at org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:248)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)
	at py4j.Gateway.invoke(Gateway.java:282)
	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
	at py4j.commands.CallCommand.execute(CallCommand.java:79)
	at py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)
	at py4j.ClientServerConnection.run(ClientServerConnection.java:106)
	at java.base/java.lang.Thread.run(Thread.java:829)
Caused by: org.elasticsearch.hadoop.EsHadoopIllegalArgumentException: Cannot determine write shards for [spark_data]; likely its format is incorrect (maybe it contains illegal characters? or all shards failed?)
	at org.elasticsearch.hadoop.util.Assert.isTrue(Assert.java:60)
	at org.elasticsearch.hadoop.rest.RestService.initSingleIndex(RestService.java:689)
	at org.elasticsearch.hadoop.rest.RestService.createWriter(RestService.java:634)
	at org.elasticsearch.spark.rdd.EsRDDWriter.write(EsRDDWriter.scala:71)
	at org.elasticsearch.spark.sql.EsSparkSQL$.$anonfun$saveToEs$1(EsSparkSQL.scala:103)
	at org.elasticsearch.spark.sql.EsSparkSQL$.$anonfun$saveToEs$1$adapted(EsSparkSQL.scala:103)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)
	at org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)
	at org.apache.spark.scheduler.Task.run(Task.scala:141)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	... 1 more
[2025-04-30T10:25:30.047+0000] {logging_mixin.py:154} INFO - [INFO] Processing file 11/34: /opt/***/data/generated_data_19.csv
[2025-04-30T10:25:38.535+0000] {logging_mixin.py:154} INFO - [INFO] File /opt/***/data/generated_data_19.csv successfully read with 2000000 rows.
[2025-04-30T10:25:38.536+0000] {logging_mixin.py:154} INFO - [INFO] Applying sampling transformation...
[2025-04-30T10:25:39.428+0000] {logging_mixin.py:154} INFO - [INFO] Sampled DataFrame has 600874 rows.
[2025-04-30T10:25:39.429+0000] {logging_mixin.py:154} INFO - [INFO] Writing to Elasticsearch...
[2025-04-30T10:26:23.219+0000] {logging_mixin.py:154} INFO - [SUCCESS] Successfully processed and indexed: /opt/***/data/generated_data_19.csv
[2025-04-30T10:26:23.220+0000] {logging_mixin.py:154} INFO - [INFO] Processing file 12/34: /opt/***/data/generated_data_2.csv
[2025-04-30T10:26:37.935+0000] {logging_mixin.py:154} INFO - [INFO] File /opt/***/data/generated_data_2.csv successfully read with 2000000 rows.
[2025-04-30T10:26:37.937+0000] {logging_mixin.py:154} INFO - [INFO] Applying sampling transformation...
[2025-04-30T10:26:39.014+0000] {logging_mixin.py:154} INFO - [INFO] Sampled DataFrame has 600870 rows.
[2025-04-30T10:26:39.015+0000] {logging_mixin.py:154} INFO - [INFO] Writing to Elasticsearch...
[2025-04-30T10:27:02.537+0000] {local_task_job_runner.py:294} WARNING - State of this instance has been externally set to restarting. Terminating instance.
[2025-04-30T10:27:02.552+0000] {process_utils.py:131} INFO - Sending 15 to group 232. PIDs of all processes in the group: [233, 232]
[2025-04-30T10:27:02.558+0000] {process_utils.py:86} INFO - Sending the signal 15 to group 232
[2025-04-30T10:27:02.563+0000] {taskinstance.py:1632} ERROR - Received SIGTERM. Terminating subprocesses.
[2025-04-30T10:27:02.565+0000] {clientserver.py:538} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/py4j/clientserver.py", line 511, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.8/socket.py", line 669, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskinstance.py", line 1634, in signal_handler
    raise AirflowException("Task received SIGTERM signal")
airflow.exceptions.AirflowException: Task received SIGTERM signal
[2025-04-30T10:27:02.587+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2025-04-30T10:27:02.594+0000] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/py4j/clientserver.py", line 511, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.8/socket.py", line 669, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskinstance.py", line 1634, in signal_handler
    raise AirflowException("Task received SIGTERM signal")
airflow.exceptions.AirflowException: Task received SIGTERM signal

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.8/site-packages/py4j/clientserver.py", line 539, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2025-04-30T10:27:02.616+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2025-04-30T10:27:02.618+0000] {logging_mixin.py:154} INFO - [ERROR] Failed to process file /opt/***/data/generated_data_2.csv: An error occurred while calling o215.save
[2025-04-30T10:27:02.619+0000] {logging_mixin.py:154} INFO - [INFO] Processing file 13/34: /opt/***/data/generated_data_20.csv
[2025-04-30T10:27:03.925+0000] {logging_mixin.py:154} INFO - [ERROR] Failed to process file /opt/***/data/generated_data_20.csv: An error occurred while calling o219.csv.
: java.lang.IllegalStateException: Cannot call methods on a stopped SparkContext.
This stopped SparkContext was created at:

org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:58)
java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)
py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)
py4j.Gateway.invoke(Gateway.java:238)
py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)
py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)
py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)
py4j.ClientServerConnection.run(ClientServerConnection.java:106)
java.base/java.lang.Thread.run(Thread.java:829)

The currently active SparkContext was created at:

org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:58)
java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)
py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)
py4j.Gateway.invoke(Gateway.java:238)
py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)
py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)
py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)
py4j.ClientServerConnection.run(ClientServerConnection.java:106)
java.base/java.lang.Thread.run(Thread.java:829)
         
	at org.apache.spark.SparkContext.assertNotStopped(SparkContext.scala:122)
	at org.apache.spark.SparkContext.broadcastInternal(SparkContext.scala:1659)
	at org.apache.spark.SparkContext.broadcast(SparkContext.scala:1644)
	at org.apache.spark.sql.execution.datasources.text.TextFileFormat.buildReader(TextFileFormat.scala:106)
	at org.apache.spark.sql.execution.datasources.FileFormat.buildReaderWithPartitionValues(FileFormat.scala:138)
	at org.apache.spark.sql.execution.datasources.FileFormat.buildReaderWithPartitionValues$(FileFormat.scala:129)
	at org.apache.spark.sql.execution.datasources.TextBasedFileFormat.buildReaderWithPartitionValues(FileFormat.scala:346)
	at org.apache.spark.sql.execution.FileSourceScanExec.inputRDD$lzycompute(DataSourceScanExec.scala:548)
	at org.apache.spark.sql.execution.FileSourceScanExec.inputRDD(DataSourceScanExec.scala:537)
	at org.apache.spark.sql.execution.FileSourceScanExec.doExecute(DataSourceScanExec.scala:575)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$execute$1(SparkPlan.scala:195)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$executeQuery$1(SparkPlan.scala:246)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
	at org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:243)
	at org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:191)
	at org.apache.spark.sql.execution.InputAdapter.inputRDD(WholeStageCodegenExec.scala:527)
	at org.apache.spark.sql.execution.InputRDDCodegen.inputRDDs(WholeStageCodegenExec.scala:455)
	at org.apache.spark.sql.execution.InputRDDCodegen.inputRDDs$(WholeStageCodegenExec.scala:454)
	at org.apache.spark.sql.execution.InputAdapter.inputRDDs(WholeStageCodegenExec.scala:498)
	at org.apache.spark.sql.execution.FilterExec.inputRDDs(basicPhysicalOperators.scala:242)
	at org.apache.spark.sql.execution.WholeStageCodegenExec.doExecute(WholeStageCodegenExec.scala:751)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$execute$1(SparkPlan.scala:195)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$executeQuery$1(SparkPlan.scala:246)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
	at org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:243)
	at org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:191)
	at org.apache.spark.sql.execution.SparkPlan.getByteArrayRdd(SparkPlan.scala:364)
	at org.apache.spark.sql.execution.SparkPlan.executeTake(SparkPlan.scala:498)
	at org.apache.spark.sql.execution.SparkPlan.executeTake(SparkPlan.scala:483)
	at org.apache.spark.sql.execution.CollectLimitExec.executeCollect(limit.scala:61)
	at org.apache.spark.sql.Dataset.collectFromPlan(Dataset.scala:4344)
	at org.apache.spark.sql.Dataset.$anonfun$head$1(Dataset.scala:3326)
	at org.apache.spark.sql.Dataset.$anonfun$withAction$2(Dataset.scala:4334)
	at org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:546)
	at org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:4332)
	at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)
	at org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)
	at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)
	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)
	at org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)
	at org.apache.spark.sql.Dataset.withAction(Dataset.scala:4332)
	at org.apache.spark.sql.Dataset.head(Dataset.scala:3326)
	at org.apache.spark.sql.Dataset.take(Dataset.scala:3549)
	at org.apache.spark.sql.execution.datasources.csv.TextInputCSVDataSource$.infer(CSVDataSource.scala:111)
	at org.apache.spark.sql.execution.datasources.csv.CSVDataSource.inferSchema(CSVDataSource.scala:64)
	at org.apache.spark.sql.execution.datasources.csv.CSVFileFormat.inferSchema(CSVFileFormat.scala:62)
	at org.apache.spark.sql.execution.datasources.DataSource.$anonfun$getOrInferFileFormatSchema$11(DataSource.scala:208)
	at scala.Option.orElse(Option.scala:447)
	at org.apache.spark.sql.execution.datasources.DataSource.getOrInferFileFormatSchema(DataSource.scala:205)
	at org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:407)
	at org.apache.spark.sql.DataFrameReader.loadV1Source(DataFrameReader.scala:229)
	at org.apache.spark.sql.DataFrameReader.$anonfun$load$2(DataFrameReader.scala:211)
	at scala.Option.getOrElse(Option.scala:189)
	at org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:211)
	at org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:538)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)
	at py4j.Gateway.invoke(Gateway.java:282)
	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
	at py4j.commands.CallCommand.execute(CallCommand.java:79)
	at py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)
	at py4j.ClientServerConnection.run(ClientServerConnection.java:106)
	at java.base/java.lang.Thread.run(Thread.java:829)
[2025-04-30T10:27:03.928+0000] {logging_mixin.py:154} INFO - [INFO] Processing file 14/34: /opt/***/data/generated_data_21.csv
[2025-04-30T10:27:05.395+0000] {clientserver.py:538} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/py4j/clientserver.py", line 516, in send_command
    raise Py4JNetworkError("Answer from Java side is empty")
py4j.protocol.Py4JNetworkError: Answer from Java side is empty
[2025-04-30T10:27:05.401+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2025-04-30T10:27:05.403+0000] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/py4j/clientserver.py", line 516, in send_command
    raise Py4JNetworkError("Answer from Java side is empty")
py4j.protocol.Py4JNetworkError: Answer from Java side is empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.8/site-packages/py4j/clientserver.py", line 539, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2025-04-30T10:27:05.407+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2025-04-30T10:27:05.409+0000] {logging_mixin.py:154} INFO - [ERROR] Failed to process file /opt/***/data/generated_data_21.csv: An error occurred while calling o39.read
[2025-04-30T10:27:05.410+0000] {logging_mixin.py:154} INFO - [INFO] Processing file 15/34: /opt/***/data/generated_data_22.csv
[2025-04-30T10:27:05.412+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2025-04-30T10:27:05.414+0000] {logging_mixin.py:154} INFO - [ERROR] Failed to process file /opt/***/data/generated_data_22.csv: [Errno 111] Connection refused
[2025-04-30T10:27:05.416+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2025-04-30T10:27:05.417+0000] {logging_mixin.py:154} INFO - [INFO] Processing file 16/34: /opt/***/data/generated_data_23.csv
[2025-04-30T10:27:05.419+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2025-04-30T10:27:05.420+0000] {logging_mixin.py:154} INFO - [ERROR] Failed to process file /opt/***/data/generated_data_23.csv: [Errno 111] Connection refused
[2025-04-30T10:27:05.421+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2025-04-30T10:27:05.422+0000] {logging_mixin.py:154} INFO - [INFO] Processing file 17/34: /opt/***/data/generated_data_24.csv
[2025-04-30T10:27:05.424+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2025-04-30T10:27:05.425+0000] {logging_mixin.py:154} INFO - [ERROR] Failed to process file /opt/***/data/generated_data_24.csv: [Errno 111] Connection refused
[2025-04-30T10:27:05.426+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2025-04-30T10:27:05.427+0000] {logging_mixin.py:154} INFO - [INFO] Processing file 18/34: /opt/***/data/generated_data_25.csv
[2025-04-30T10:27:05.428+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2025-04-30T10:27:05.429+0000] {logging_mixin.py:154} INFO - [ERROR] Failed to process file /opt/***/data/generated_data_25.csv: [Errno 111] Connection refused
[2025-04-30T10:27:05.430+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2025-04-30T10:27:05.431+0000] {logging_mixin.py:154} INFO - [INFO] Processing file 19/34: /opt/***/data/generated_data_26.csv
[2025-04-30T10:27:05.433+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2025-04-30T10:27:05.434+0000] {logging_mixin.py:154} INFO - [ERROR] Failed to process file /opt/***/data/generated_data_26.csv: [Errno 111] Connection refused
[2025-04-30T10:27:05.435+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2025-04-30T10:27:05.435+0000] {logging_mixin.py:154} INFO - [INFO] Processing file 20/34: /opt/***/data/generated_data_27.csv
[2025-04-30T10:27:05.437+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2025-04-30T10:27:05.438+0000] {logging_mixin.py:154} INFO - [ERROR] Failed to process file /opt/***/data/generated_data_27.csv: [Errno 111] Connection refused
[2025-04-30T10:27:05.439+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2025-04-30T10:27:05.440+0000] {logging_mixin.py:154} INFO - [INFO] Processing file 21/34: /opt/***/data/generated_data_28.csv
[2025-04-30T10:27:05.441+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2025-04-30T10:27:05.442+0000] {logging_mixin.py:154} INFO - [ERROR] Failed to process file /opt/***/data/generated_data_28.csv: [Errno 111] Connection refused
[2025-04-30T10:27:05.443+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2025-04-30T10:27:05.444+0000] {logging_mixin.py:154} INFO - [INFO] Processing file 22/34: /opt/***/data/generated_data_29.csv
[2025-04-30T10:27:05.445+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2025-04-30T10:27:05.446+0000] {logging_mixin.py:154} INFO - [ERROR] Failed to process file /opt/***/data/generated_data_29.csv: [Errno 111] Connection refused
[2025-04-30T10:27:05.447+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2025-04-30T10:27:05.447+0000] {logging_mixin.py:154} INFO - [INFO] Processing file 23/34: /opt/***/data/generated_data_3.csv
[2025-04-30T10:27:05.449+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2025-04-30T10:27:05.450+0000] {logging_mixin.py:154} INFO - [ERROR] Failed to process file /opt/***/data/generated_data_3.csv: [Errno 111] Connection refused
[2025-04-30T10:27:05.451+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2025-04-30T10:27:05.451+0000] {logging_mixin.py:154} INFO - [INFO] Processing file 24/34: /opt/***/data/generated_data_30.csv
[2025-04-30T10:27:05.453+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2025-04-30T10:27:05.454+0000] {logging_mixin.py:154} INFO - [ERROR] Failed to process file /opt/***/data/generated_data_30.csv: [Errno 111] Connection refused
[2025-04-30T10:27:05.455+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2025-04-30T10:27:05.456+0000] {logging_mixin.py:154} INFO - [INFO] Processing file 25/34: /opt/***/data/generated_data_31.csv
[2025-04-30T10:27:05.457+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2025-04-30T10:27:05.458+0000] {logging_mixin.py:154} INFO - [ERROR] Failed to process file /opt/***/data/generated_data_31.csv: [Errno 111] Connection refused
[2025-04-30T10:27:05.459+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2025-04-30T10:27:05.460+0000] {logging_mixin.py:154} INFO - [INFO] Processing file 26/34: /opt/***/data/generated_data_32.csv
[2025-04-30T10:27:05.461+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2025-04-30T10:27:05.462+0000] {logging_mixin.py:154} INFO - [ERROR] Failed to process file /opt/***/data/generated_data_32.csv: [Errno 111] Connection refused
[2025-04-30T10:27:05.463+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2025-04-30T10:27:05.464+0000] {logging_mixin.py:154} INFO - [INFO] Processing file 27/34: /opt/***/data/generated_data_33.csv
[2025-04-30T10:27:05.465+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2025-04-30T10:27:05.466+0000] {logging_mixin.py:154} INFO - [ERROR] Failed to process file /opt/***/data/generated_data_33.csv: [Errno 111] Connection refused
[2025-04-30T10:27:05.468+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2025-04-30T10:27:05.469+0000] {logging_mixin.py:154} INFO - [INFO] Processing file 28/34: /opt/***/data/generated_data_34.csv
[2025-04-30T10:27:05.471+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2025-04-30T10:27:05.472+0000] {logging_mixin.py:154} INFO - [ERROR] Failed to process file /opt/***/data/generated_data_34.csv: [Errno 111] Connection refused
[2025-04-30T10:27:05.473+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2025-04-30T10:27:05.474+0000] {logging_mixin.py:154} INFO - [INFO] Processing file 29/34: /opt/***/data/generated_data_4.csv
[2025-04-30T10:27:05.475+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2025-04-30T10:27:05.476+0000] {logging_mixin.py:154} INFO - [ERROR] Failed to process file /opt/***/data/generated_data_4.csv: [Errno 111] Connection refused
[2025-04-30T10:27:05.477+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2025-04-30T10:27:05.478+0000] {logging_mixin.py:154} INFO - [INFO] Processing file 30/34: /opt/***/data/generated_data_5.csv
[2025-04-30T10:27:05.480+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2025-04-30T10:27:05.481+0000] {logging_mixin.py:154} INFO - [ERROR] Failed to process file /opt/***/data/generated_data_5.csv: [Errno 111] Connection refused
[2025-04-30T10:27:05.482+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2025-04-30T10:27:05.482+0000] {logging_mixin.py:154} INFO - [INFO] Processing file 31/34: /opt/***/data/generated_data_6.csv
[2025-04-30T10:27:05.483+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2025-04-30T10:27:05.485+0000] {logging_mixin.py:154} INFO - [ERROR] Failed to process file /opt/***/data/generated_data_6.csv: [Errno 111] Connection refused
[2025-04-30T10:27:05.485+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2025-04-30T10:27:05.486+0000] {logging_mixin.py:154} INFO - [INFO] Processing file 32/34: /opt/***/data/generated_data_7.csv
[2025-04-30T10:27:05.487+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2025-04-30T10:27:05.489+0000] {logging_mixin.py:154} INFO - [ERROR] Failed to process file /opt/***/data/generated_data_7.csv: [Errno 111] Connection refused
[2025-04-30T10:27:05.489+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2025-04-30T10:27:05.490+0000] {logging_mixin.py:154} INFO - [INFO] Processing file 33/34: /opt/***/data/generated_data_8.csv
[2025-04-30T10:27:05.491+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2025-04-30T10:27:05.493+0000] {logging_mixin.py:154} INFO - [ERROR] Failed to process file /opt/***/data/generated_data_8.csv: [Errno 111] Connection refused
[2025-04-30T10:27:05.493+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2025-04-30T10:27:05.494+0000] {logging_mixin.py:154} INFO - [INFO] Processing file 34/34: /opt/***/data/generated_data_9.csv
[2025-04-30T10:27:05.496+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2025-04-30T10:27:05.497+0000] {logging_mixin.py:154} INFO - [ERROR] Failed to process file /opt/***/data/generated_data_9.csv: [Errno 111] Connection refused
[2025-04-30T10:27:05.498+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2025-04-30T10:27:05.498+0000] {logging_mixin.py:154} INFO - [INFO] Stopping Spark session.
[2025-04-30T10:27:05.500+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2025-04-30T10:27:05.501+0000] {logging_mixin.py:154} INFO - [FATAL] Spark processing failed: [Errno 111] Connection refused
[2025-04-30T10:27:05.502+0000] {clientserver.py:543} INFO - Closing down clientserver connection
[2025-04-30T10:27:05.502+0000] {python.py:194} INFO - Done. Returned value was: Failed: [Errno 111] Connection refused
[2025-04-30T10:27:05.631+0000] {taskinstance.py:1400} INFO - Marking task as SUCCESS. dag_id=POC_orange_data2, task_id=spark_task2, execution_date=20250430T101732, start_date=20250430T101733, end_date=20250430T102705
[2025-04-30T10:27:05.773+0000] {process_utils.py:79} INFO - Process psutil.Process(pid=233, status='terminated', started='10:17:33') (233) terminated with exit code None
[2025-04-30T10:27:05.777+0000] {process_utils.py:79} INFO - Process psutil.Process(pid=232, status='terminated', exitcode=0, started='10:17:33') (232) terminated with exit code 0
